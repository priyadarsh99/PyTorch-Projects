{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\nnltk.download('gutenberg')\nfrom nltk.corpus import gutenberg\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:37.827109Z","iopub.execute_input":"2024-11-25T15:11:37.827747Z","iopub.status.idle":"2024-11-25T15:11:39.913867Z","shell.execute_reply.started":"2024-11-25T15:11:37.827696Z","shell.execute_reply":"2024-11-25T15:11:39.913000Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package gutenberg to /usr/share/nltk_data...\n[nltk_data]   Package gutenberg is already up-to-date!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:39.915391Z","iopub.execute_input":"2024-11-25T15:11:39.915759Z","iopub.status.idle":"2024-11-25T15:11:50.729726Z","shell.execute_reply.started":"2024-11-25T15:11:39.915733Z","shell.execute_reply":"2024-11-25T15:11:50.729026Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:50.730689Z","iopub.execute_input":"2024-11-25T15:11:50.731131Z","iopub.status.idle":"2024-11-25T15:11:50.742020Z","shell.execute_reply.started":"2024-11-25T15:11:50.731105Z","shell.execute_reply":"2024-11-25T15:11:50.741279Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Loading the dataset\ndata = gutenberg.raw('austen-persuasion.txt') \n#Save to a File\nwith open('Pride&Prejudice.txt','w') as file:\n    file.write(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:50.743819Z","iopub.execute_input":"2024-11-25T15:11:50.744068Z","iopub.status.idle":"2024-11-25T15:11:50.756506Z","shell.execute_reply.started":"2024-11-25T15:11:50.744044Z","shell.execute_reply":"2024-11-25T15:11:50.755860Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Loading the text file\nwith open('Pride&Prejudice.txt','r') as file:\n    text = file.read().lower()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:50.757616Z","iopub.execute_input":"2024-11-25T15:11:50.757971Z","iopub.status.idle":"2024-11-25T15:11:50.763073Z","shell.execute_reply.started":"2024-11-25T15:11:50.757927Z","shell.execute_reply":"2024-11-25T15:11:50.762148Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#Tokenizing the text & creating the indexes for words\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts([text])\ntotal_words = len(tokenizer.word_index)+1\ntotal_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:50.764082Z","iopub.execute_input":"2024-11-25T15:11:50.764402Z","iopub.status.idle":"2024-11-25T15:11:50.818774Z","shell.execute_reply.started":"2024-11-25T15:11:50.764367Z","shell.execute_reply":"2024-11-25T15:11:50.818059Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"5875"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenizer.word_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:50.819480Z","iopub.execute_input":"2024-11-25T15:11:50.819699Z","iopub.status.idle":"2024-11-25T15:11:50.839610Z","shell.execute_reply.started":"2024-11-25T15:11:50.819677Z","shell.execute_reply":"2024-11-25T15:11:50.838730Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'the': 1,\n 'to': 2,\n 'and': 3,\n 'of': 4,\n 'a': 5,\n 'in': 6,\n 'was': 7,\n 'her': 8,\n 'had': 9,\n 'she': 10,\n 'i': 11,\n 'it': 12,\n 'he': 13,\n 'be': 14,\n 'not': 15,\n 'that': 16,\n 'as': 17,\n 'for': 18,\n 'but': 19,\n 'his': 20,\n 'with': 21,\n 'you': 22,\n 'have': 23,\n 'at': 24,\n 'all': 25,\n 'been': 26,\n 'him': 27,\n 'could': 28,\n 'anne': 29,\n 'very': 30,\n 'they': 31,\n 'were': 32,\n 'by': 33,\n 'which': 34,\n 'is': 35,\n 'on': 36,\n 'so': 37,\n 'no': 38,\n 'would': 39,\n 'captain': 40,\n 'from': 41,\n 'their': 42,\n 'mrs': 43,\n 'there': 44,\n 'or': 45,\n 'more': 46,\n 'them': 47,\n 'mr': 48,\n 'elliot': 49,\n 'this': 50,\n 'an': 51,\n 'than': 52,\n 'one': 53,\n 'must': 54,\n 'when': 55,\n 'my': 56,\n 'being': 57,\n 'only': 58,\n 'lady': 59,\n 'such': 60,\n 'do': 61,\n 'much': 62,\n 'if': 63,\n 'any': 64,\n 'what': 65,\n 'who': 66,\n 'wentworth': 67,\n 'should': 68,\n 'me': 69,\n 'good': 70,\n 'little': 71,\n 'said': 72,\n 'will': 73,\n 'might': 74,\n 'own': 75,\n 'well': 76,\n 'did': 77,\n 'herself': 78,\n 'now': 79,\n 'never': 80,\n 'charles': 81,\n 'we': 82,\n 'time': 83,\n 'sir': 84,\n 'think': 85,\n 'are': 86,\n 'other': 87,\n 'nothing': 88,\n 'some': 89,\n 'again': 90,\n 'great': 91,\n 'too': 92,\n 'man': 93,\n 'know': 94,\n 'am': 95,\n 'how': 96,\n 'miss': 97,\n 'your': 98,\n 'walter': 99,\n 'most': 100,\n 'see': 101,\n 'soon': 102,\n 'mary': 103,\n 'russell': 104,\n 'though': 105,\n 'before': 106,\n 'two': 107,\n 'first': 108,\n 'quite': 109,\n 'musgrove': 110,\n 'always': 111,\n 'without': 112,\n 'can': 113,\n 'every': 114,\n 'bath': 115,\n 'has': 116,\n 'louisa': 117,\n 'into': 118,\n 'about': 119,\n 'after': 120,\n 'made': 121,\n 'himself': 122,\n 'long': 123,\n 'out': 124,\n 'father': 125,\n 'house': 126,\n 'say': 127,\n 'seemed': 128,\n 'having': 129,\n 'up': 130,\n 'thought': 131,\n 'however': 132,\n 'last': 133,\n 'make': 134,\n 'go': 135,\n 'place': 136,\n 'may': 137,\n 'better': 138,\n 'many': 139,\n 'over': 140,\n 'same': 141,\n 'young': 142,\n 'found': 143,\n 'home': 144,\n 'elizabeth': 145,\n 'room': 146,\n 'like': 147,\n 'family': 148,\n 'felt': 149,\n 'give': 150,\n 'away': 151,\n 'way': 152,\n 'ever': 153,\n 'uppercross': 154,\n 'friend': 155,\n 'come': 156,\n 'feelings': 157,\n 'still': 158,\n 'day': 159,\n 'done': 160,\n 'kellynch': 161,\n 'sure': 162,\n 'sister': 163,\n 'its': 164,\n 'those': 165,\n 'upon': 166,\n 'enough': 167,\n 'even': 168,\n 'then': 169,\n 'while': 170,\n 'back': 171,\n 'off': 172,\n 'came': 173,\n 'lyme': 174,\n 'just': 175,\n 'henrietta': 176,\n 'benwick': 177,\n 'present': 178,\n 'another': 179,\n 'our': 180,\n 'going': 181,\n 'heard': 182,\n 'mind': 183,\n 'happy': 184,\n 'something': 185,\n 'indeed': 186,\n 'here': 187,\n 'harville': 188,\n 'few': 189,\n 'smith': 190,\n 'acquaintance': 191,\n 'down': 192,\n 'knew': 193,\n 'admiral': 194,\n 'party': 195,\n 'almost': 196,\n 'rather': 197,\n 'half': 198,\n 'moment': 199,\n 'woman': 200,\n 'morning': 201,\n 'years': 202,\n 'seen': 203,\n 'yet': 204,\n 'wish': 205,\n 'once': 206,\n 'perhaps': 207,\n 'clay': 208,\n 'shall': 209,\n 'dear': 210,\n 'look': 211,\n 'oh': 212,\n 'between': 213,\n 'poor': 214,\n 'together': 215,\n 'others': 216,\n 'evening': 217,\n 'hope': 218,\n 'these': 219,\n 'ought': 220,\n 'till': 221,\n 'gone': 222,\n 'take': 223,\n 'saw': 224,\n 'where': 225,\n \"anne's\": 226,\n 'character': 227,\n 'life': 228,\n 'known': 229,\n 'anything': 230,\n 'left': 231,\n 'believe': 232,\n 'certainly': 233,\n 'us': 234,\n 'yes': 235,\n 'old': 236,\n 'side': 237,\n 'short': 238,\n 'cried': 239,\n 'leave': 240,\n 'since': 241,\n 'near': 242,\n 'possible': 243,\n 'deal': 244,\n 'looking': 245,\n 'croft': 246,\n 'best': 247,\n 'under': 248,\n 'feel': 249,\n 'interest': 250,\n 'really': 251,\n 'right': 252,\n 'everything': 253,\n 'perfectly': 254,\n 'manner': 255,\n 'each': 256,\n 'does': 257,\n 'least': 258,\n 'next': 259,\n 'whole': 260,\n 'part': 261,\n 'cannot': 262,\n 'looked': 263,\n 'course': 264,\n 'love': 265,\n 'heart': 266,\n 'three': 267,\n 'thing': 268,\n 'name': 269,\n 'spirits': 270,\n 'sort': 271,\n 'wife': 272,\n 'nor': 273,\n 'passed': 274,\n 'idea': 275,\n 'both': 276,\n 'hardly': 277,\n 'pleasure': 278,\n 'among': 279,\n 'hear': 280,\n 'musgroves': 281,\n 'people': 282,\n 'agreeable': 283,\n 'themselves': 284,\n 'seeing': 285,\n 'visit': 286,\n 'company': 287,\n 'account': 288,\n 'feeling': 289,\n 'hayter': 290,\n 'afterwards': 291,\n 'either': 292,\n 'ill': 293,\n 'get': 294,\n \"elliot's\": 295,\n 'world': 296,\n 'head': 297,\n 'whom': 298,\n 'walk': 299,\n 'children': 300,\n 'country': 301,\n 'received': 302,\n 'through': 303,\n 'change': 304,\n 'general': 305,\n 'fine': 306,\n 'mother': 307,\n 'brought': 308,\n 'given': 309,\n 'consequence': 310,\n 'eyes': 311,\n 'coming': 312,\n 'manners': 313,\n 'wanted': 314,\n 'glad': 315,\n 'began': 316,\n 'determined': 317,\n 'tell': 318,\n 'letter': 319,\n 'end': 320,\n 'object': 321,\n 'word': 322,\n 'talked': 323,\n 'far': 324,\n 'set': 325,\n 'men': 326,\n 'towards': 327,\n 'whether': 328,\n 'happiness': 329,\n 'state': 330,\n 'put': 331,\n 'replied': 332,\n 'spoke': 333,\n 'want': 334,\n 'answer': 335,\n 'myself': 336,\n 'hour': 337,\n 'called': 338,\n \"russell's\": 339,\n 'brother': 340,\n 'less': 341,\n 'often': 342,\n 'obliged': 343,\n 'able': 344,\n 'husband': 345,\n 'went': 346,\n 'full': 347,\n 'conversation': 348,\n 'wallis': 349,\n 'person': 350,\n 'friends': 351,\n 'strong': 352,\n 'fortune': 353,\n 'immediately': 354,\n 'gave': 355,\n 'point': 356,\n 'hours': 357,\n 'talk': 358,\n 'understand': 359,\n 'camden': 360,\n 'hall': 361,\n 'pretty': 362,\n 'therefore': 363,\n 'thinking': 364,\n 'doing': 365,\n 'wished': 366,\n 'use': 367,\n 'walked': 368,\n 'former': 369,\n 'bad': 370,\n 'return': 371,\n 'high': 372,\n 'year': 373,\n 'situation': 374,\n 'sensible': 375,\n 'marriage': 376,\n 'met': 377,\n 'else': 378,\n 'shepherd': 379,\n 'subject': 380,\n 'against': 381,\n 'gentleman': 382,\n 'let': 383,\n 'returned': 384,\n 'attention': 385,\n \"'\": 386,\n 'acquainted': 387,\n \"wentworth's\": 388,\n 'beginning': 389,\n 'new': 390,\n 'considered': 391,\n 'marry': 392,\n 'early': 393,\n 'different': 394,\n 'longer': 395,\n 'used': 396,\n 'doubt': 397,\n 'taken': 398,\n 'because': 399,\n 'speak': 400,\n 'asked': 401,\n 'told': 402,\n 'carriage': 403,\n 'minutes': 404,\n 'cousin': 405,\n 'street': 406,\n 'dalrymple': 407,\n 'attachment': 408,\n 'neither': 409,\n 'case': 410,\n 'regard': 411,\n 'business': 412,\n 'assure': 413,\n 'circumstances': 414,\n 'saying': 415,\n 'past': 416,\n 'stay': 417,\n 'week': 418,\n 'nature': 419,\n 'forward': 420,\n 'ladies': 421,\n 'chapter': 422,\n 'married': 423,\n 'appearance': 424,\n 'taking': 425,\n 'worth': 426,\n 'suppose': 427,\n 'worse': 428,\n 'added': 429,\n 'taste': 430,\n 'degree': 431,\n 'true': 432,\n 'days': 433,\n 'likely': 434,\n 'meet': 435,\n 'talking': 436,\n 'crofts': 437,\n 'eye': 438,\n 'engagement': 439,\n 'opinion': 440,\n 'things': 441,\n 'night': 442,\n 'words': 443,\n 'satisfied': 444,\n 'making': 445,\n 'hand': 446,\n \"father's\": 447,\n 'beyond': 448,\n 'surprise': 449,\n 'find': 450,\n 'mean': 451,\n 'sight': 452,\n 'child': 453,\n 'morrow': 454,\n 'door': 455,\n 'colonel': 456,\n 'usual': 457,\n 'settled': 458,\n 'four': 459,\n 'women': 460,\n 'excellent': 461,\n 'real': 462,\n 'face': 463,\n 'equal': 464,\n 'within': 465,\n 'question': 466,\n 'decided': 467,\n 'knowledge': 468,\n 'living': 469,\n 'advantage': 470,\n 'care': 471,\n 'ready': 472,\n 'frederick': 473,\n 'cottage': 474,\n 'turned': 475,\n 'whose': 476,\n 'matter': 477,\n 'help': 478,\n 'twenty': 479,\n 'speaking': 480,\n 'walking': 481,\n 'open': 482,\n 'match': 483,\n 'reason': 484,\n 'got': 485,\n 'kind': 486,\n 'spoken': 487,\n 'means': 488,\n 'believed': 489,\n 'comfort': 490,\n 'particularly': 491,\n 'sea': 492,\n 'natural': 493,\n 'alone': 494,\n 'bear': 495,\n 'meeting': 496,\n 'daughter': 497,\n 'hands': 498,\n 'influence': 499,\n 'understanding': 500,\n 'none': 501,\n 'rest': 502,\n 'health': 503,\n 'lived': 504,\n 'pain': 505,\n 'understood': 506,\n 'already': 507,\n 'need': 508,\n 'sorry': 509,\n 'air': 510,\n 'call': 511,\n 'pleased': 512,\n 'why': 513,\n 'appeared': 514,\n 'concert': 515,\n 'took': 516,\n 'handsome': 517,\n 'delighted': 518,\n 'conduct': 519,\n 'giving': 520,\n 'value': 521,\n 'nobody': 522,\n 'large': 523,\n 'sometimes': 524,\n 'self': 525,\n 'engaged': 526,\n 'anybody': 527,\n 'style': 528,\n 'notice': 529,\n 'supposed': 530,\n 'dinner': 531,\n \"musgrove's\": 532,\n 'voice': 533,\n 'cousins': 534,\n 'wonder': 535,\n 'lost': 536,\n 'terms': 537,\n \"walter's\": 538,\n 'generally': 539,\n 'drawing': 540,\n 'rooms': 541,\n 'expected': 542,\n 'money': 543,\n 'small': 544,\n 'serious': 545,\n 'anxious': 546,\n 'tone': 547,\n 'suffering': 548,\n 'circumstance': 549,\n 'disposed': 550,\n 'imagine': 551,\n 'hoped': 552,\n 'window': 553,\n 'probably': 554,\n 'also': 555,\n 'finding': 556,\n 'harvilles': 557,\n 'respect': 558,\n 'son': 559,\n \"mary's\": 560,\n 'second': 561,\n 'everybody': 562,\n 'favour': 563,\n 'observed': 564,\n 'pride': 565,\n 'proper': 566,\n 'kept': 567,\n 'hearing': 568,\n 'sense': 569,\n 'sisters': 570,\n 'entirely': 571,\n 'warm': 572,\n 'curiosity': 573,\n 'fellow': 574,\n 'turn': 575,\n 'waiting': 576,\n 'completely': 577,\n 'view': 578,\n 'history': 579,\n 'extremely': 580,\n 'loved': 581,\n 'ago': 582,\n 'meant': 583,\n 'vain': 584,\n 'drew': 585,\n 'months': 586,\n 'description': 587,\n 'particular': 588,\n 'times': 589,\n 'caught': 590,\n 'common': 591,\n 'reached': 592,\n 'farther': 593,\n 'perfect': 594,\n 'listened': 595,\n 'seem': 596,\n 'late': 597,\n 'meaning': 598,\n 'nurse': 599,\n 'followed': 600,\n 'seat': 601,\n 'youth': 602,\n 'kindness': 603,\n 'highly': 604,\n 'distress': 605,\n 'liked': 606,\n 'table': 607,\n 'town': 608,\n 'instead': 609,\n 'period': 610,\n 'claims': 611,\n 'fact': 612,\n 'remain': 613,\n 'agreed': 614,\n 'staying': 615,\n 'trying': 616,\n 'behind': 617,\n 'attending': 618,\n 'profession': 619,\n 'afraid': 620,\n 'proof': 621,\n 'answered': 622,\n 'smallest': 623,\n 'continued': 624,\n 'remember': 625,\n 'nearly': 626,\n 'allowed': 627,\n 'quiet': 628,\n 'knowing': 629,\n 'round': 630,\n 'aware': 631,\n 'low': 632,\n 'impossible': 633,\n 'exactly': 634,\n 'buildings': 635,\n 'countenance': 636,\n 'improved': 637,\n 'looks': 638,\n 'girls': 639,\n 'honour': 640,\n 'neighbourhood': 641,\n 'london': 642,\n 'consciousness': 643,\n 'fully': 644,\n 'evil': 645,\n 'future': 646,\n 'property': 647,\n 'justice': 648,\n 'difference': 649,\n 'struck': 650,\n 'live': 651,\n 'persuaded': 652,\n 'friendship': 653,\n 'turning': 654,\n 'getting': 655,\n 'keep': 656,\n 'truth': 657,\n 'trouble': 658,\n 'besides': 659,\n 'easy': 660,\n 'necessary': 661,\n 'introduced': 662,\n 'comfortable': 663,\n 'agitation': 664,\n 'ashamed': 665,\n 'sent': 666,\n 'yourself': 667,\n 'yesterday': 668,\n 'sit': 669,\n 'sat': 670,\n 'breakfast': 671,\n 'glance': 672,\n 'instantly': 673,\n 'cobb': 674,\n 'pity': 675,\n 'read': 676,\n 'heir': 677,\n 'mentioned': 678,\n 'altogether': 679,\n 'personal': 680,\n 'society': 681,\n 'fair': 682,\n 'sake': 683,\n 'enjoyment': 684,\n 'danger': 685,\n 'especially': 686,\n 'became': 687,\n 'power': 688,\n 'hint': 689,\n 'due': 690,\n 'clear': 691,\n 'itself': 692,\n 'duty': 693,\n 'severe': 694,\n 'appear': 695,\n 'fixed': 696,\n 'bring': 697,\n 'navy': 698,\n 'tenant': 699,\n 'yours': 700,\n 'extraordinary': 701,\n 'greater': 702,\n 'forget': 703,\n 'cold': 704,\n \"croft's\": 705,\n 'become': 706,\n 'along': 707,\n 'share': 708,\n 'admitted': 709,\n 'opportunity': 710,\n 'invitation': 711,\n 'pleasant': 712,\n 'occupied': 713,\n 'listen': 714,\n 'play': 715,\n 'strength': 716,\n 'dare': 717,\n 'calling': 718,\n 'dine': 719,\n 'tried': 720,\n 'smile': 721,\n 'interesting': 722,\n 'inn': 723,\n 'regret': 724,\n 'stood': 725,\n 'eldest': 726,\n 'remained': 727,\n 'placed': 728,\n 'ten': 729,\n 'begun': 730,\n 'growing': 731,\n 'certain': 732,\n 'boy': 733,\n 'plan': 734,\n 'difficulties': 735,\n 'miles': 736,\n 'desirable': 737,\n 'surprised': 738,\n 'around': 739,\n 'consider': 740,\n 'wishing': 741,\n 'recollect': 742,\n 'wait': 743,\n 'spirit': 744,\n 'temper': 745,\n 'putting': 746,\n 'exceedingly': 747,\n 'altered': 748,\n 'truly': 749,\n 'pass': 750,\n 'sick': 751,\n 'occasion': 752,\n 'eight': 753,\n 'directly': 754,\n 'letters': 755,\n 'six': 756,\n 'board': 757,\n 'five': 758,\n 'promised': 759,\n 'leaving': 760,\n 'smiling': 761,\n \"harville's\": 762,\n 'thank': 763,\n 'moments': 764,\n \"louisa's\": 765,\n 'mention': 766,\n 'carteret': 767,\n 'domestic': 768,\n 'dignity': 769,\n 'baronet': 770,\n 'rank': 771,\n 'required': 772,\n 'indulgence': 773,\n 'death': 774,\n 'age': 775,\n 'importance': 776,\n 'anxiety': 777,\n 'scarcely': 778,\n 'warmth': 779,\n 'spring': 780,\n 'rich': 781,\n 'hints': 782,\n 'spend': 783,\n 'sound': 784,\n 'horses': 785,\n 'wishes': 786,\n 'inclination': 787,\n 'satisfaction': 788,\n 'school': 789,\n 'fond': 790,\n 'pleasing': 791,\n 'spite': 792,\n 'shut': 793,\n 'confidence': 794,\n 'observe': 795,\n 'gentlemen': 796,\n 'depend': 797,\n 'reply': 798,\n 'bringing': 799,\n 'weather': 800,\n 'effect': 801,\n 'returning': 802,\n 'mere': 803,\n 'intercourse': 804,\n 'silence': 805,\n 'resolution': 806,\n 'differently': 807,\n 'opinions': 808,\n 'nice': 809,\n 'happened': 810,\n 'seems': 811,\n 'occurred': 812,\n 'elegant': 813,\n \"moment's\": 814,\n 'direction': 815,\n 'hers': 816,\n \"charles's\": 817,\n 'declare': 818,\n 'chance': 819,\n 'instant': 820,\n 'eager': 821,\n 'written': 822,\n 'useful': 823,\n 'silent': 824,\n 'servant': 825,\n 'sitting': 826,\n \"ma'am\": 827,\n 'considering': 828,\n 'winthrop': 829,\n 'arm': 830,\n 'lodgings': 831,\n 'card': 832,\n 'amusement': 833,\n 'admiration': 834,\n 'opened': 835,\n 'birth': 836,\n 'vanity': 837,\n 'beauty': 838,\n 'constant': 839,\n 'indifference': 840,\n 'rights': 841,\n 'god': 842,\n 'girl': 843,\n 'merely': 844,\n 'charm': 845,\n 'credit': 846,\n 'properly': 847,\n 'books': 848,\n 'forced': 849,\n 'invited': 850,\n 'several': 851,\n 'summer': 852,\n 'sentiments': 853,\n 'confess': 854,\n 'expect': 855,\n 'ideas': 856,\n 'seven': 857,\n 'affected': 858,\n 'painful': 859,\n 'sooner': 860,\n 'winter': 861,\n 'lately': 862,\n 'reach': 863,\n 'peace': 864,\n 'wanting': 865,\n 'order': 866,\n 'mine': 867,\n 'fit': 868,\n 'nay': 869,\n 'service': 870,\n 'report': 871,\n 'gratitude': 872,\n 'connexion': 873,\n 'actually': 874,\n 'astonishment': 875,\n 'produced': 876,\n 'tenderness': 877,\n 'continually': 878,\n 'wrong': 879,\n 'misery': 880,\n 'ended': 881,\n 'suspense': 882,\n 'superiority': 883,\n 'humour': 884,\n 'autumn': 885,\n 'begin': 886,\n 'creature': 887,\n 'happen': 888,\n 'excepting': 889,\n 'joined': 890,\n 'avoid': 891,\n \"sister's\": 892,\n 'suffer': 893,\n 're': 894,\n 'evidently': 895,\n 'join': 896,\n 'ask': 897,\n 'fancied': 898,\n 'dr': 899,\n 'promise': 900,\n 'evident': 901,\n 'smiled': 902,\n 'sensations': 903,\n 'november': 904,\n 'month': 905,\n 'lord': 906,\n 'blessing': 907,\n 'inferior': 908,\n 'claim': 909,\n 'superior': 910,\n 'quit': 911,\n 'intimate': 912,\n 'village': 913,\n 'widow': 914,\n \"mother's\": 915,\n 'features': 916,\n 'excite': 917,\n 'work': 918,\n 'follow': 919,\n 'closed': 920,\n 'following': 921,\n 'equally': 922,\n 'interval': 923,\n 'admit': 924,\n 'solicitude': 925,\n 'thoughts': 926,\n 'views': 927,\n 'recommend': 928,\n 'quick': 929,\n 'capable': 930,\n 'complete': 931,\n 'distance': 932,\n 'dreadful': 933,\n 'suit': 934,\n 'secret': 935,\n 'intimacy': 936,\n 'affection': 937,\n 'dangerous': 938,\n 'companion': 939,\n 'removal': 940,\n 'war': 941,\n 'matters': 942,\n 'thus': 943,\n 'venture': 944,\n \"clay's\": 945,\n 'safe': 946,\n 'pause': 947,\n 'hard': 948,\n 'allow': 949,\n 'persons': 950,\n 'convinced': 951,\n 'fell': 952,\n 'possibility': 953,\n 'contrary': 954,\n 'ay': 955,\n 'highest': 956,\n 'hopes': 957,\n 'imagined': 958,\n 'except': 959,\n 'cheerful': 960,\n 'nerves': 961,\n 'recollection': 962,\n 'proved': 963,\n 'compliments': 964,\n 'weeks': 965,\n 'divided': 966,\n 'absence': 967,\n 'warmly': 968,\n 'fall': 969,\n 'escape': 970,\n 'arrived': 971,\n 'soul': 972,\n 'stopped': 973,\n 'enquiries': 974,\n 'subjects': 975,\n 'dress': 976,\n 'otherwise': 977,\n 'listening': 978,\n 'indifferent': 979,\n 'visited': 980,\n 'anywhere': 981,\n 'necessity': 982,\n 'thirty': 983,\n 'forgotten': 984,\n 'praise': 985,\n 'arrival': 986,\n 'send': 987,\n 'attend': 988,\n 'motive': 989,\n 'quietly': 990,\n 'try': 991,\n 'desire': 992,\n 'ah': 993,\n 'entered': 994,\n 'comprehend': 995,\n 'pray': 996,\n 'suffered': 997,\n 'tired': 998,\n 'attentions': 999,\n 'sounds': 1000,\n ...}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#Creating input sequence\ninput_sequences = []\nfor line in text.split('\\n'):\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1,len(token_list)):\n        n_gram_sequences = token_list[:i+1]\n        input_sequences.append(n_gram_sequences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:50.840729Z","iopub.execute_input":"2024-11-25T15:11:50.841400Z","iopub.status.idle":"2024-11-25T15:11:51.140402Z","shell.execute_reply.started":"2024-11-25T15:11:50.841375Z","shell.execute_reply":"2024-11-25T15:11:51.139775Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"input_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.141290Z","iopub.execute_input":"2024-11-25T15:11:51.141528Z","iopub.status.idle":"2024-11-25T15:11:51.220047Z","shell.execute_reply.started":"2024-11-25T15:11:51.141504Z","shell.execute_reply":"2024-11-25T15:11:51.219312Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[[1103, 33],\n [1103, 33, 3293],\n [1103, 33, 3293, 3294],\n [1103, 33, 3293, 3294, 3295],\n [422, 1953],\n [84, 99],\n [84, 99, 49],\n [84, 99, 49, 4],\n [84, 99, 49, 4, 161],\n [84, 99, 49, 4, 161, 361],\n [84, 99, 49, 4, 161, 361, 6],\n [84, 99, 49, 4, 161, 361, 6, 1646],\n [84, 99, 49, 4, 161, 361, 6, 1646, 7],\n [84, 99, 49, 4, 161, 361, 6, 1646, 7, 5],\n [84, 99, 49, 4, 161, 361, 6, 1646, 7, 5, 93],\n [84, 99, 49, 4, 161, 361, 6, 1646, 7, 5, 93, 66],\n [18, 20],\n [18, 20, 75],\n [18, 20, 75, 833],\n [18, 20, 75, 833, 80],\n [18, 20, 75, 833, 80, 516],\n [18, 20, 75, 833, 80, 516, 130],\n [18, 20, 75, 833, 80, 516, 130, 64],\n [18, 20, 75, 833, 80, 516, 130, 64, 1009],\n [18, 20, 75, 833, 80, 516, 130, 64, 1009, 19],\n [18, 20, 75, 833, 80, 516, 130, 64, 1009, 19, 1],\n [18, 20, 75, 833, 80, 516, 130, 64, 1009, 19, 1, 2422],\n [44, 13],\n [44, 13, 143],\n [44, 13, 143, 1418],\n [44, 13, 143, 1418, 18],\n [44, 13, 143, 1418, 18, 51],\n [44, 13, 143, 1418, 18, 51, 1954],\n [44, 13, 143, 1418, 18, 51, 1954, 337],\n [44, 13, 143, 1418, 18, 51, 1954, 337, 3],\n [44, 13, 143, 1418, 18, 51, 1954, 337, 3, 1647],\n [44, 13, 143, 1418, 18, 51, 1954, 337, 3, 1647, 6],\n [44, 13, 143, 1418, 18, 51, 1954, 337, 3, 1647, 6, 5],\n [1224, 53],\n [1224, 53, 44],\n [1224, 53, 44, 20],\n [1224, 53, 44, 20, 3296],\n [1224, 53, 44, 20, 3296, 32],\n [1224, 53, 44, 20, 3296, 32, 1010],\n [1224, 53, 44, 20, 3296, 32, 1010, 118],\n [1224, 53, 44, 20, 3296, 32, 1010, 118, 834],\n [1224, 53, 44, 20, 3296, 32, 1010, 118, 834, 3],\n [558, 33],\n [558, 33, 3297],\n [558, 33, 3297, 1],\n [558, 33, 3297, 1, 2423],\n [558, 33, 3297, 1, 2423, 3298],\n [558, 33, 3297, 1, 2423, 3298, 4],\n [558, 33, 3297, 1, 2423, 3298, 4, 1],\n [558, 33, 3297, 1, 2423, 3298, 4, 1, 1648],\n [558, 33, 3297, 1, 2423, 3298, 4, 1, 1648, 3299],\n [44, 64],\n [44, 64, 1955],\n [44, 64, 1955, 903],\n [44, 64, 1955, 903, 2424],\n [44, 64, 1955, 903, 2424, 41],\n [44, 64, 1955, 903, 2424, 41, 768],\n [44, 64, 1955, 903, 2424, 41, 768, 1011],\n [1012, 1225],\n [1012, 1225, 118],\n [1012, 1225, 118, 675],\n [1012, 1225, 118, 675, 3],\n [1012, 1225, 118, 675, 3, 1419],\n [1012, 1225, 118, 675, 3, 1419, 17],\n [1012, 1225, 118, 675, 3, 1419, 17, 13],\n [1012, 1225, 118, 675, 3, 1419, 17, 13, 475],\n [1012, 1225, 118, 675, 3, 1419, 17, 13, 475, 140],\n [1, 196],\n [1, 196, 3300],\n [1, 196, 3300, 2425],\n [1, 196, 3300, 2425, 4],\n [1, 196, 3300, 2425, 4, 1],\n [1, 196, 3300, 2425, 4, 1, 133],\n [1, 196, 3300, 2425, 4, 1, 133, 3301],\n [1, 196, 3300, 2425, 4, 1, 133, 3301, 3],\n [1, 196, 3300, 2425, 4, 1, 133, 3301, 3, 44],\n [63, 114],\n [63, 114, 87],\n [63, 114, 87, 3302],\n [63, 114, 87, 3302, 32],\n [63, 114, 87, 3302, 32, 3303],\n [63, 114, 87, 3302, 32, 3303, 13],\n [63, 114, 87, 3302, 32, 3303, 13, 28],\n [63, 114, 87, 3302, 32, 3303, 13, 28, 676],\n [63, 114, 87, 3302, 32, 3303, 13, 28, 676, 20],\n [63, 114, 87, 3302, 32, 3303, 13, 28, 676, 20, 75],\n [63, 114, 87, 3302, 32, 3303, 13, 28, 676, 20, 75, 579],\n [21, 51],\n [21, 51, 250],\n [21, 51, 250, 34],\n [21, 51, 250, 34, 80],\n [21, 51, 250, 34, 80, 1226],\n [21, 51, 250, 34, 80, 1226, 50],\n [21, 51, 250, 34, 80, 1226, 50, 7],\n [21, 51, 250, 34, 80, 1226, 50, 7, 1],\n [21, 51, 250, 34, 80, 1226, 50, 7, 1, 2426],\n [21, 51, 250, 34, 80, 1226, 50, 7, 1, 2426, 24],\n [21, 51, 250, 34, 80, 1226, 50, 7, 1, 2426, 24, 34],\n [1, 1013],\n [1, 1013, 1649],\n [1, 1013, 1649, 111],\n [1, 1013, 1649, 111, 835],\n [49, 4],\n [49, 4, 161],\n [49, 4, 161, 361],\n [99, 49],\n [99, 49, 1227],\n [99, 49, 1227, 3304],\n [99, 49, 1227, 3304, 1953],\n [99, 49, 1227, 3304, 1953, 3305],\n [99, 49, 1227, 3304, 1953, 3305, 423],\n [99, 49, 1227, 3304, 1953, 3305, 423, 2427],\n [99, 49, 1227, 3304, 1953, 3305, 423, 2427, 2428],\n [99, 49, 1227, 3304, 1953, 3305, 423, 2427, 2428, 3306],\n [99, 49, 1227, 3304, 1953, 3305, 423, 2427, 2428, 3306, 145],\n [497, 4],\n [497, 4, 1228],\n [497, 4, 1228, 3307],\n [497, 4, 1228, 3307, 1420],\n [497, 4, 1228, 3307, 1420, 4],\n [497, 4, 1228, 3307, 1420, 4, 2429],\n [497, 4, 1228, 3307, 1420, 4, 2429, 1650],\n [497, 4, 1228, 3307, 1420, 4, 2429, 1650, 6],\n [497, 4, 1228, 3307, 1420, 4, 2429, 1650, 6, 1],\n [497, 4, 1228, 3307, 1420, 4, 2429, 1650, 6, 1, 1651],\n [497, 4, 1228, 3307, 1420, 4, 2429, 1650, 6, 1, 1651, 4],\n [3308, 33],\n [3308, 33, 34],\n [3308, 33, 34, 59],\n [3308, 33, 34, 59, 66],\n [3308, 33, 34, 59, 66, 1104],\n [3308, 33, 34, 59, 66, 1104, 3309],\n [3308, 33, 34, 59, 66, 1104, 3309, 13],\n [3308, 33, 34, 59, 66, 1104, 3309, 13, 116],\n [3308, 33, 34, 59, 66, 1104, 3309, 13, 116, 3310],\n [3308, 33, 34, 59, 66, 1104, 3309, 13, 116, 3310, 145],\n [1227, 1956],\n [1227, 1956, 1953],\n [1227, 1956, 1953, 3311],\n [1227, 1956, 1953, 3311, 29],\n [1227, 1956, 1953, 3311, 29, 1227],\n [1227, 1956, 1953, 3311, 29, 1227, 2430],\n [1227, 1956, 1953, 3311, 29, 1227, 2430, 2431],\n [1227, 1956, 1953, 3311, 29, 1227, 2430, 2431, 3312],\n [1227, 1956, 1953, 3311, 29, 1227, 2430, 2431, 3312, 5],\n [1227, 1956, 1953, 3311, 29, 1227, 2430, 2431, 3312, 5, 158],\n [1227, 1956, 1953, 3311, 29, 1227, 2430, 2431, 3312, 5, 158, 1227],\n [1227, 1956, 1953, 3311, 29, 1227, 2430, 2431, 3312, 5, 158, 1227, 559],\n [904, 1957],\n [904, 1957, 3313],\n [904, 1957, 3313, 103],\n [904, 1957, 3313, 103, 1227],\n [904, 1957, 3313, 103, 1227, 904],\n [904, 1957, 3313, 103, 1227, 904, 2432],\n [904, 1957, 3313, 103, 1227, 904, 2432, 3314],\n [1229, 60],\n [1229, 60, 9],\n [1229, 60, 9, 1],\n [1229, 60, 9, 1, 2433],\n [1229, 60, 9, 1, 2433, 1958],\n [1229, 60, 9, 1, 2433, 1958, 725],\n [1229, 60, 9, 1, 2433, 1958, 725, 41],\n [1229, 60, 9, 1, 2433, 1958, 725, 41, 1],\n [1229, 60, 9, 1, 2433, 1958, 725, 41, 1, 3315],\n [1229, 60, 9, 1, 2433, 1958, 725, 41, 1, 3315, 498],\n [19, 84],\n [19, 84, 99],\n [19, 84, 99, 9],\n [19, 84, 99, 9, 637],\n [19, 84, 99, 9, 637, 12],\n [19, 84, 99, 9, 637, 12, 33],\n [19, 84, 99, 9, 637, 12, 33, 1652],\n [19, 84, 99, 9, 637, 12, 33, 1652, 18],\n [19, 84, 99, 9, 637, 12, 33, 1652, 18, 1],\n [19, 84, 99, 9, 637, 12, 33, 1652, 18, 1, 1230],\n [19, 84, 99, 9, 637, 12, 33, 1652, 18, 1, 1230, 4],\n [122, 3],\n [122, 3, 20],\n [122, 3, 20, 148],\n [122, 3, 20, 148, 219],\n [122, 3, 20, 148, 219, 443],\n [122, 3, 20, 148, 219, 443, 120],\n [122, 3, 20, 148, 219, 443, 120, 1],\n [122, 3, 20, 148, 219, 443, 120, 1, 1959],\n [122, 3, 20, 148, 219, 443, 120, 1, 1959, 4],\n [122, 3, 20, 148, 219, 443, 120, 1, 1959, 4, 560],\n [122, 3, 20, 148, 219, 443, 120, 1, 1959, 4, 560, 836],\n [423, 3316],\n [423, 3316, 2434],\n [423, 3316, 2434, 3317],\n [423, 3316, 2434, 3317, 81],\n [423, 3316, 2434, 3317, 81, 559],\n [423, 3316, 2434, 3317, 81, 559, 3],\n [423, 3316, 2434, 3317, 81, 559, 3, 677],\n [423, 3316, 2434, 3317, 81, 559, 3, 677, 4],\n [423, 3316, 2434, 3317, 81, 559, 3, 677, 4, 81],\n [110, 1420],\n [110, 1420, 4],\n [110, 1420, 4, 154],\n [110, 1420, 4, 154, 6],\n [110, 1420, 4, 154, 6, 1],\n [110, 1420, 4, 154, 6, 1, 1651],\n [110, 1420, 4, 154, 6, 1, 1651, 4],\n [110, 1420, 4, 154, 6, 1, 1651, 4, 2435],\n [3, 33],\n [3, 33, 3318],\n [3, 33, 3318, 100],\n [3, 33, 3318, 100, 3319],\n [3, 33, 3318, 100, 3319, 1],\n [3, 33, 3318, 100, 3319, 1, 159],\n [3, 33, 3318, 100, 3319, 1, 159, 4],\n [3, 33, 3318, 100, 3319, 1, 159, 4, 1],\n [3, 33, 3318, 100, 3319, 1, 159, 4, 1, 905],\n [3, 33, 3318, 100, 3319, 1, 159, 4, 1, 905, 36],\n [3, 33, 3318, 100, 3319, 1, 159, 4, 1, 905, 36, 34],\n [13, 9],\n [13, 9, 536],\n [13, 9, 536, 20],\n [13, 9, 536, 20, 272],\n [169, 600],\n [169, 600, 1],\n [169, 600, 1, 579],\n [169, 600, 1, 579, 3],\n [169, 600, 1, 579, 3, 1231],\n [169, 600, 1, 579, 3, 1231, 4],\n [169, 600, 1, 579, 3, 1231, 4, 1],\n [169, 600, 1, 579, 3, 1231, 4, 1, 1960],\n [169, 600, 1, 579, 3, 1231, 4, 1, 1960, 3],\n [169, 600, 1, 579, 3, 1231, 4, 1, 1960, 3, 1421],\n [169, 600, 1, 579, 3, 1231, 4, 1, 1960, 3, 1421, 148],\n [6, 1],\n [6, 1, 457],\n [6, 1, 457, 537],\n [6, 1, 457, 537, 96],\n [6, 1, 457, 537, 96, 12],\n [6, 1, 457, 537, 96, 12, 9],\n [6, 1, 457, 537, 96, 12, 9, 26],\n [6, 1, 457, 537, 96, 12, 9, 26, 108],\n [6, 1, 457, 537, 96, 12, 9, 26, 108, 458],\n [6, 1, 457, 537, 96, 12, 9, 26, 108, 458, 6],\n [6, 1, 457, 537, 96, 12, 9, 26, 108, 458, 6, 3320],\n [96, 678],\n [96, 678, 6],\n [96, 678, 6, 3321],\n [96, 678, 6, 3321, 3322],\n [96, 678, 6, 3321, 3322, 1],\n [96, 678, 6, 3321, 3322, 1, 1422],\n [96, 678, 6, 3321, 3322, 1, 1422, 4],\n [96, 678, 6, 3321, 3322, 1, 1422, 4, 372],\n [96, 678, 6, 3321, 3322, 1, 1422, 4, 372, 3323],\n [2436, 5],\n [2436, 5, 3324],\n [2436, 5, 3324, 6],\n [2436, 5, 3324, 6, 267],\n [2436, 5, 3324, 6, 267, 2437],\n [2436, 5, 3324, 6, 267, 2437, 3325],\n [1653, 4],\n [1653, 4, 3326],\n [1653, 4, 3326, 3],\n [1653, 4, 3326, 3, 769],\n [1653, 4, 3326, 3, 769, 4],\n [1653, 4, 3326, 3, 769, 4, 770],\n [1653, 4, 3326, 3, 769, 4, 770, 6],\n [1653, 4, 3326, 3, 769, 4, 770, 6, 1],\n [1653, 4, 3326, 3, 769, 4, 770, 6, 1, 108],\n [1653, 4, 3326, 3, 769, 4, 770, 6, 1, 108, 373],\n [4, 81],\n [4, 81, 3327],\n [4, 81, 3327, 21],\n [4, 81, 3327, 21, 25],\n [4, 81, 3327, 21, 25, 1],\n [4, 81, 3327, 21, 25, 1, 3328],\n [4, 81, 3327, 21, 25, 1, 3328, 3],\n [4, 81, 3327, 21, 25, 1, 3328, 3, 3329],\n [4, 81, 3327, 21, 25, 1, 3328, 3, 3329, 31],\n [4, 81, 3327, 21, 25, 1, 3328, 3, 3329, 31, 9],\n [4, 81, 3327, 21, 25, 1, 3328, 3, 3329, 31, 9, 423],\n [1654, 679],\n [1654, 679, 107],\n [1654, 679, 107, 517],\n [1654, 679, 107, 517, 3330],\n [1654, 679, 107, 517, 3330, 3331],\n [1654, 679, 107, 517, 3330, 3331, 3],\n [1654, 679, 107, 517, 3330, 3331, 3, 2438],\n [1654, 679, 107, 517, 3330, 3331, 3, 2438, 21],\n [1, 1014],\n [1, 1014, 3],\n [1, 1014, 3, 2439],\n [1, 1014, 3, 2439, 1015],\n [1, 1014, 3, 2439, 1015, 601],\n [1, 1014, 3, 2439, 1015, 601, 161],\n [1, 1014, 3, 2439, 1015, 601, 161, 361],\n [1, 1014, 3, 2439, 1015, 601, 161, 361, 6],\n [1, 1014, 3, 2439, 1015, 601, 161, 361, 6, 1],\n [1, 1014, 3, 2439, 1015, 601, 161, 361, 6, 1, 1651],\n [4, 2435],\n [4, 2435, 3],\n [4, 2435, 3, 84],\n [4, 2435, 3, 84, 538],\n [4, 2435, 3, 84, 538, 3332],\n [4, 2435, 3, 84, 538, 3332, 90],\n [4, 2435, 3, 84, 538, 3332, 90, 6],\n [4, 2435, 3, 84, 538, 3332, 90, 6, 50],\n [4, 2435, 3, 84, 538, 3332, 90, 6, 50, 3333],\n [677, 1961],\n [677, 1961, 1655],\n [677, 1961, 1655, 99],\n [677, 1961, 1655, 99, 49],\n [677, 1961, 1655, 99, 49, 1420],\n [677, 1961, 1655, 99, 49, 1420, 91],\n [677, 1961, 1655, 99, 49, 1420, 91, 2440],\n [677, 1961, 1655, 99, 49, 1420, 91, 2440, 4],\n [1, 561],\n [1, 561, 84],\n [1, 561, 84, 99],\n [837, 7],\n [837, 7, 1],\n [837, 7, 1, 389],\n [837, 7, 1, 389, 3],\n [837, 7, 1, 389, 3, 1],\n [837, 7, 1, 389, 3, 1, 320],\n [837, 7, 1, 389, 3, 1, 320, 4],\n [837, 7, 1, 389, 3, 1, 320, 4, 84],\n [837, 7, 1, 389, 3, 1, 320, 4, 84, 99],\n [837, 7, 1, 389, 3, 1, 320, 4, 84, 99, 295],\n [837, 7, 1, 389, 3, 1, 320, 4, 84, 99, 295, 227],\n [837, 4],\n [837, 4, 350],\n [837, 4, 350, 3],\n [837, 4, 350, 3, 4],\n [837, 4, 350, 3, 4, 374],\n [837, 4, 350, 3, 4, 374, 13],\n [837, 4, 350, 3, 4, 374, 13, 9],\n [837, 4, 350, 3, 4, 374, 13, 9, 26],\n [837, 4, 350, 3, 4, 374, 13, 9, 26, 1962],\n [837, 4, 350, 3, 4, 374, 13, 9, 26, 1962, 517],\n [6, 20],\n [6, 20, 602],\n [6, 20, 602, 3],\n [6, 20, 602, 3, 24],\n [6, 20, 602, 3, 24, 1232],\n [6, 20, 602, 3, 24, 1232, 459],\n [6, 20, 602, 3, 24, 1232, 459, 7],\n [6, 20, 602, 3, 24, 1232, 459, 7, 158],\n [6, 20, 602, 3, 24, 1232, 459, 7, 158, 5],\n [6, 20, 602, 3, 24, 1232, 459, 7, 158, 5, 30],\n [6, 20, 602, 3, 24, 1232, 459, 7, 158, 5, 30, 306],\n [6, 20, 602, 3, 24, 1232, 459, 7, 158, 5, 30, 306, 93],\n [189, 460],\n [189, 460, 28],\n [189, 460, 28, 85],\n [189, 460, 28, 85, 46],\n [189, 460, 28, 85, 46, 4],\n [189, 460, 28, 85, 46, 4, 42],\n [189, 460, 28, 85, 46, 4, 42, 680],\n [189, 460, 28, 85, 46, 4, 42, 680, 424],\n [189, 460, 28, 85, 46, 4, 42, 680, 424, 52],\n [189, 460, 28, 85, 46, 4, 42, 680, 424, 52, 13],\n [189, 460, 28, 85, 46, 4, 42, 680, 424, 52, 13, 77],\n [273, 28],\n [273, 28, 1],\n [273, 28, 1, 3334],\n [273, 28, 1, 3334, 4],\n [273, 28, 1, 3334, 4, 64],\n [273, 28, 1, 3334, 4, 64, 390],\n [273, 28, 1, 3334, 4, 64, 390, 121],\n [273, 28, 1, 3334, 4, 64, 390, 121, 906],\n [273, 28, 1, 3334, 4, 64, 390, 121, 906, 14],\n [273, 28, 1, 3334, 4, 64, 390, 121, 906, 14, 46],\n [273, 28, 1, 3334, 4, 64, 390, 121, 906, 14, 46, 518],\n [273, 28, 1, 3334, 4, 64, 390, 121, 906, 14, 46, 518, 21],\n [1, 136],\n [1, 136, 13],\n [1, 136, 13, 1105],\n [1, 136, 13, 1105, 6],\n [1, 136, 13, 1105, 6, 681],\n [1, 136, 13, 1105, 6, 681, 13],\n [1, 136, 13, 1105, 6, 681, 13, 391],\n [1, 136, 13, 1105, 6, 681, 13, 391, 1],\n [1, 136, 13, 1105, 6, 681, 13, 391, 1, 907],\n [1, 136, 13, 1105, 6, 681, 13, 391, 1, 907, 4],\n [1, 136, 13, 1105, 6, 681, 13, 391, 1, 907, 4, 838],\n [17, 908],\n [17, 908, 58],\n [17, 908, 58, 2],\n [17, 908, 58, 2, 1],\n [17, 908, 58, 2, 1, 907],\n [17, 908, 58, 2, 1, 907, 4],\n [17, 908, 58, 2, 1, 907, 4, 5],\n [17, 908, 58, 2, 1, 907, 4, 5, 2441],\n [17, 908, 58, 2, 1, 907, 4, 5, 2441, 3],\n [17, 908, 58, 2, 1, 907, 4, 5, 2441, 3, 1],\n [17, 908, 58, 2, 1, 907, 4, 5, 2441, 3, 1, 84],\n [17, 908, 58, 2, 1, 907, 4, 5, 2441, 3, 1, 84, 99],\n [17, 908, 58, 2, 1, 907, 4, 5, 2441, 3, 1, 84, 99, 49],\n [66, 1656],\n [66, 1656, 219],\n [66, 1656, 219, 3335],\n [66, 1656, 219, 3335, 7],\n [66, 1656, 219, 3335, 7, 1],\n [66, 1656, 219, 3335, 7, 1, 839],\n [66, 1656, 219, 3335, 7, 1, 839, 321],\n [66, 1656, 219, 3335, 7, 1, 839, 321, 4],\n [66, 1656, 219, 3335, 7, 1, 839, 321, 4, 20],\n [66, 1656, 219, 3335, 7, 1, 839, 321, 4, 20, 2442],\n [66, 1656, 219, 3335, 7, 1, 839, 321, 4, 20, 2442, 558],\n [3, 2443],\n [20, 70],\n [20, 70, 638],\n [20, 70, 638, 3],\n [20, 70, 638, 3, 20],\n [20, 70, 638, 3, 20, 771],\n [20, 70, 638, 3, 20, 771, 9],\n [20, 70, 638, 3, 20, 771, 9, 53],\n [20, 70, 638, 3, 20, 771, 9, 53, 682],\n [20, 70, 638, 3, 20, 771, 9, 53, 682, 909],\n [20, 70, 638, 3, 20, 771, 9, 53, 682, 909, 36],\n [20, 70, 638, 3, 20, 771, 9, 53, 682, 909, 36, 20],\n [20, 70, 638, 3, 20, 771, 9, 53, 682, 909, 36, 20, 408],\n [241, 2],\n [241, 2, 47],\n [241, 2, 47, 13],\n [241, 2, 47, 13, 54],\n [241, 2, 47, 13, 54, 23],\n [241, 2, 47, 13, 54, 23, 1657],\n [241, 2, 47, 13, 54, 23, 1657, 5],\n [241, 2, 47, 13, 54, 23, 1657, 5, 272],\n [241, 2, 47, 13, 54, 23, 1657, 5, 272, 4],\n [241, 2, 47, 13, 54, 23, 1657, 5, 272, 4, 30],\n [241, 2, 47, 13, 54, 23, 1657, 5, 272, 4, 30, 910],\n [241, 2, 47, 13, 54, 23, 1657, 5, 272, 4, 30, 910, 227],\n [2, 64],\n [2, 64, 268],\n [2, 64, 268, 1016],\n [2, 64, 268, 1016, 33],\n [2, 64, 268, 1016, 33, 20],\n [2, 64, 268, 1016, 33, 20, 75],\n [2, 64, 268, 1016, 33, 20, 75, 59],\n [2, 64, 268, 1016, 33, 20, 75, 59, 49],\n [2, 64, 268, 1016, 33, 20, 75, 59, 49, 9],\n [2, 64, 268, 1016, 33, 20, 75, 59, 49, 9, 26],\n [2, 64, 268, 1016, 33, 20, 75, 59, 49, 9, 26, 51],\n [2, 64, 268, 1016, 33, 20, 75, 59, 49, 9, 26, 51, 461],\n [2, 64, 268, 1016, 33, 20, 75, 59, 49, 9, 26, 51, 461, 200],\n [375, 3],\n [375, 3, 1106],\n [375, 3, 1106, 476],\n [375, 3, 1106, 476, 1017],\n [375, 3, 1106, 476, 1017, 3],\n [375, 3, 1106, 476, 1017, 3, 519],\n [375, 3, 1106, 476, 1017, 3, 519, 63],\n [375, 3, 1106, 476, 1017, 3, 519, 63, 31],\n [375, 3, 1106, 476, 1017, 3, 519, 63, 31, 74],\n [375, 3, 1106, 476, 1017, 3, 519, 63, 31, 74, 14],\n [1963, 1],\n [1963, 1, 3336],\n [1963, 1, 3336, 3337],\n [1963, 1, 3336, 3337, 34],\n [1963, 1, 3336, 3337, 34, 121],\n [1963, 1, 3336, 3337, 34, 121, 8],\n [1963, 1, 3336, 3337, 34, 121, 8, 59],\n [1963, 1, 3336, 3337, 34, 121, 8, 59, 49],\n [9, 80],\n [9, 80, 772],\n [9, 80, 772, 773],\n [9, 80, 772, 773, 291],\n [9, 80, 772, 773, 291, 10],\n [9, 80, 772, 773, 291, 10, 9],\n [9, 80, 772, 773, 291, 10, 9, 1233],\n [45, 1964],\n [45, 1964, 45],\n [45, 1964, 45, 2444],\n [45, 1964, 45, 2444, 20],\n [45, 1964, 45, 2444, 20, 3338],\n [45, 1964, 45, 2444, 20, 3338, 3],\n [45, 1964, 45, 2444, 20, 3338, 3, 3339],\n [45, 1964, 45, 2444, 20, 3338, 3, 3339, 20],\n [45, 1964, 45, 2444, 20, 3338, 3, 3339, 20, 462],\n [1423, 18],\n [1423, 18, 1965],\n [1423, 18, 1965, 202],\n [1423, 18, 1965, 202, 3],\n [1423, 18, 1965, 202, 3, 105],\n [1423, 18, 1965, 202, 3, 105, 15],\n [1423, 18, 1965, 202, 3, 105, 15, 1],\n [1423, 18, 1965, 202, 3, 105, 15, 1, 30],\n [1423, 18, 1965, 202, 3, 105, 15, 1, 30, 1234],\n [57, 6],\n [57, 6, 1],\n [57, 6, 1, 296],\n [57, 6, 1, 296, 78],\n [57, 6, 1, 296, 78, 9],\n [57, 6, 1, 296, 78, 9, 143],\n [57, 6, 1, 296, 78, 9, 143, 167],\n [57, 6, 1, 296, 78, 9, 143, 167, 6],\n [57, 6, 1, 296, 78, 9, 143, 167, 6, 8],\n [57, 6, 1, 296, 78, 9, 143, 167, 6, 8, 1658],\n [57, 6, 1, 296, 78, 9, 143, 167, 6, 8, 1658, 8],\n [57, 6, 1, 296, 78, 9, 143, 167, 6, 8, 1658, 8, 351],\n [3, 8],\n [3, 8, 300],\n [3, 8, 300, 2],\n [3, 8, 300, 2, 1659],\n [3, 8, 300, 2, 1659, 8],\n [3, 8, 300, 2, 1659, 8, 2],\n [3, 8, 300, 2, 1659, 8, 2, 228],\n [3, 8, 300, 2, 1659, 8, 2, 228, 3],\n [3, 8, 300, 2, 1659, 8, 2, 228, 3, 134],\n [3, 8, 300, 2, 1659, 8, 2, 228, 3, 134, 12],\n [3, 8, 300, 2, 1659, 8, 2, 228, 3, 134, 12, 38],\n [3, 8, 300, 2, 1659, 8, 2, 228, 3, 134, 12, 38, 477],\n [3, 8, 300, 2, 1659, 8, 2, 228, 3, 134, 12, 38, 477, 4],\n [840, 2],\n [840, 2, 8],\n [840, 2, 8, 55],\n [840, 2, 8, 55, 10],\n [840, 2, 8, 55, 10, 7],\n [840, 2, 8, 55, 10, 7, 338],\n [840, 2, 8, 55, 10, 7, 338, 36],\n [840, 2, 8, 55, 10, 7, 338, 36, 2],\n [840, 2, 8, 55, 10, 7, 338, 36, 2, 911],\n [840, 2, 8, 55, 10, 7, 338, 36, 2, 911, 47],\n [267, 639],\n [267, 639, 1],\n [267, 639, 1, 107],\n [267, 639, 1, 107, 726],\n [267, 639, 1, 107, 726, 2445],\n [267, 639, 1, 107, 726, 2445, 3],\n [267, 639, 1, 107, 726, 2445, 3, 1966],\n [267, 639, 1, 107, 726, 2445, 3, 1966, 7],\n [267, 639, 1, 107, 726, 2445, 3, 1966, 7, 51],\n [267, 639, 1, 107, 726, 2445, 3, 1966, 7, 51, 1967],\n [267, 639, 1, 107, 726, 2445, 3, 1966, 7, 51, 1967, 3340],\n [18, 5],\n [18, 5, 307],\n [18, 5, 307, 2],\n [18, 5, 307, 2, 3341],\n [18, 5, 307, 2, 3341, 51],\n [18, 5, 307, 2, 3341, 51, 1967],\n [18, 5, 307, 2, 3341, 51, 1967, 2446],\n [18, 5, 307, 2, 3341, 51, 1967, 2446, 197],\n [18, 5, 307, 2, 3341, 51, 1967, 2446, 197, 2],\n [18, 5, 307, 2, 3341, 51, 1967, 2446, 197, 2, 3342],\n [18, 5, 307, 2, 3341, 51, 1967, 2446, 197, 2, 3342, 2],\n [1, 1107],\n [1, 1107, 3],\n [1, 1107, 3, 1968],\n [1, 1107, 3, 1968, 4],\n [1, 1107, 3, 1968, 4, 5],\n [1, 1107, 3, 1968, 4, 5, 3343],\n [1, 1107, 3, 1968, 4, 5, 3343, 1660],\n [1, 1107, 3, 1968, 4, 5, 3343, 1660, 125],\n [10, 9],\n [10, 9, 132],\n [10, 9, 132, 53],\n [10, 9, 132, 53, 30],\n [10, 9, 132, 53, 30, 912],\n [10, 9, 132, 53, 30, 912, 155],\n [10, 9, 132, 53, 30, 912, 155, 5],\n [10, 9, 132, 53, 30, 912, 155, 5, 375],\n [10, 9, 132, 53, 30, 912, 155, 5, 375, 1661],\n [10, 9, 132, 53, 30, 912, 155, 5, 375, 1661, 200],\n [66, 9],\n [66, 9, 26],\n [66, 9, 26, 308],\n [66, 9, 26, 308, 33],\n [66, 9, 26, 308, 33, 352],\n [66, 9, 26, 308, 33, 352, 408],\n [66, 9, 26, 308, 33, 352, 408, 2],\n [66, 9, 26, 308, 33, 352, 408, 2, 78],\n [66, 9, 26, 308, 33, 352, 408, 2, 78, 2],\n [66, 9, 26, 308, 33, 352, 408, 2, 78, 2, 1108],\n [1109, 33],\n [1109, 33, 8],\n [1109, 33, 8, 6],\n [1109, 33, 8, 6, 1],\n [1109, 33, 8, 6, 1, 913],\n [1109, 33, 8, 6, 1, 913, 4],\n [1109, 33, 8, 6, 1, 913, 4, 161],\n [1109, 33, 8, 6, 1, 913, 4, 161, 3],\n [1109, 33, 8, 6, 1, 913, 4, 161, 3, 36],\n [1109, 33, 8, 6, 1, 913, 4, 161, 3, 36, 8],\n [1109, 33, 8, 6, 1, 913, 4, 161, 3, 36, 8, 603],\n [1109, 33, 8, 6, 1, 913, 4, 161, 3, 36, 8, 603, 3],\n [1109, 33, 8, 6, 1, 913, 4, 161, 3, 36, 8, 603, 3, 1424],\n [59, 49],\n [59, 49, 3344],\n [59, 49, 3344, 2447],\n [59, 49, 3344, 2447, 18],\n [59, 49, 3344, 2447, 18, 1],\n [59, 49, 3344, 2447, 18, 1, 247],\n [59, 49, 3344, 2447, 18, 1, 247, 478],\n [59, 49, 3344, 2447, 18, 1, 247, 478, 3],\n [59, 49, 3344, 2447, 18, 1, 247, 478, 3, 3345],\n [59, 49, 3344, 2447, 18, 1, 247, 478, 3, 3345, 4],\n [1, 70],\n [1, 70, 1969],\n [1, 70, 1969, 3],\n [1, 70, 1969, 3, 3346],\n [1, 70, 1969, 3, 3346, 34],\n [1, 70, 1969, 3, 3346, 34, 10],\n [1, 70, 1969, 3, 3346, 34, 10, 9],\n [1, 70, 1969, 3, 3346, 34, 10, 9, 26],\n [1, 70, 1969, 3, 3346, 34, 10, 9, 26, 1662],\n [520, 8],\n [520, 8, 1110],\n [50, 155],\n [50, 155, 3],\n [50, 155, 3, 84],\n [50, 155, 3, 84, 99],\n [50, 155, 3, 84, 99, 77],\n [50, 155, 3, 84, 99, 77, 15],\n [50, 155, 3, 84, 99, 77, 15, 392],\n [50, 155, 3, 84, 99, 77, 15, 392, 1018],\n [50, 155, 3, 84, 99, 77, 15, 392, 1018, 74],\n [50, 155, 3, 84, 99, 77, 15, 392, 1018, 74, 23],\n [50, 155, 3, 84, 99, 77, 15, 392, 1018, 74, 23, 26],\n [2448, 36],\n [2448, 36, 16],\n [2448, 36, 16, 297],\n [2448, 36, 16, 297, 33],\n [2448, 36, 16, 297, 33, 42],\n [2448, 36, 16, 297, 33, 42, 191],\n [2448, 36, 16, 297, 33, 42, 191, 1235],\n [2448, 36, 16, 297, 33, 42, 191, 1235, 202],\n [9, 274],\n [9, 274, 151],\n [9, 274, 151, 241],\n [9, 274, 151, 241, 59],\n [9, 274, 151, 241, 59, 295],\n [9, 274, 151, 241, 59, 295, 774],\n [9, 274, 151, 241, 59, 295, 774, 3],\n [9, 274, 151, 241, 59, 295, 774, 3, 31],\n [9, 274, 151, 241, 59, 295, 774, 3, 31, 32],\n [9, 274, 151, 241, 59, 295, 774, 3, 31, 32, 158],\n [242, 1111],\n [242, 1111, 3],\n [242, 1111, 3, 912],\n [242, 1111, 3, 912, 351],\n [242, 1111, 3, 912, 351, 3],\n [242, 1111, 3, 912, 351, 3, 53],\n [242, 1111, 3, 912, 351, 3, 53, 727],\n [242, 1111, 3, 912, 351, 3, 53, 727, 5],\n [242, 1111, 3, 912, 351, 3, 53, 727, 5, 2449],\n [1, 87],\n [1, 87, 5],\n [1, 87, 5, 914],\n [16, 59],\n [16, 59, 104],\n [16, 59, 104, 4],\n [16, 59, 104, 4, 1112],\n [16, 59, 104, 4, 1112, 775],\n [16, 59, 104, 4, 1112, 775, 3],\n [16, 59, 104, 4, 1112, 775, 3, 227],\n [16, 59, 104, 4, 1112, 775, 3, 227, 3],\n [16, 59, 104, 4, 1112, 775, 3, 227, 3, 580],\n [76, 1970],\n [76, 1970, 18],\n [76, 1970, 18, 68],\n [76, 1970, 18, 68, 23],\n [76, 1970, 18, 68, 23, 38],\n [76, 1970, 18, 68, 23, 38, 131],\n [76, 1970, 18, 68, 23, 38, 131, 4],\n [76, 1970, 18, 68, 23, 38, 131, 4, 5],\n [76, 1970, 18, 68, 23, 38, 131, 4, 5, 561],\n [76, 1970, 18, 68, 23, 38, 131, 4, 5, 561, 376],\n [2450, 38],\n [2450, 38, 1425],\n [2450, 38, 1425, 2],\n [2450, 38, 1425, 2, 1],\n [2450, 38, 1425, 2, 1, 1019],\n [2450, 38, 1425, 2, 1, 1019, 34],\n [2450, 38, 1425, 2, 1, 1019, 34, 35],\n [2450, 38, 1425, 2, 1, 1019, 34, 35, 197],\n [2450, 38, 1425, 2, 1, 1019, 34, 35, 197, 1971],\n [2450, 38, 1425, 2, 1, 1019, 34, 35, 197, 1971, 2],\n [2450, 38, 1425, 2, 1, 1019, 34, 35, 197, 1971, 2, 14],\n [2450, 38, 1425, 2, 1, 1019, 34, 35, 197, 1971, 2, 14, 3347],\n [3348, 55],\n [3348, 55, 5],\n [3348, 55, 5, 200],\n [3348, 55, 5, 200, 257],\n [3348, 55, 5, 200, 257, 392],\n [3348, 55, 5, 200, 257, 392, 90],\n [3348, 55, 5, 200, 257, 392, 90, 52],\n [3348, 55, 5, 200, 257, 392, 90, 52, 55],\n [3348, 55, 5, 200, 257, 392, 90, 52, 55, 10],\n [3348, 55, 5, 200, 257, 392, 90, 52, 55, 10, 257],\n [3348, 55, 5, 200, 257, 392, 90, 52, 55, 10, 257, 15],\n [19, 84],\n [19, 84, 538],\n [19, 84, 538, 1426],\n [19, 84, 538, 1426, 6],\n [19, 84, 538, 1426, 6, 3349],\n [19, 84, 538, 1426, 6, 3349, 2451],\n [19, 84, 538, 1426, 6, 3349, 2451, 1236],\n [14, 12],\n [14, 12, 229],\n [14, 12, 229, 169],\n [14, 12, 229, 169, 16],\n [14, 12, 229, 169, 16, 84],\n [14, 12, 229, 169, 16, 84, 99],\n [14, 12, 229, 169, 16, 84, 99, 147],\n [14, 12, 229, 169, 16, 84, 99, 147, 5],\n [14, 12, 229, 169, 16, 84, 99, 147, 5, 70],\n [14, 12, 229, 169, 16, 84, 99, 147, 5, 70, 125],\n [14, 12, 229, 169, 16, 84, 99, 147, 5, 70, 125, 129],\n [14, 12, 229, 169, 16, 84, 99, 147, 5, 70, 125, 129, 377],\n [14, 12, 229, 169, 16, 84, 99, 147, 5, 70, 125, 129, 377, 21],\n [53, 45],\n [53, 45, 107],\n [53, 45, 107, 1237],\n [53, 45, 107, 1237, 2452],\n [53, 45, 107, 1237, 2452, 6],\n [53, 45, 107, 1237, 2452, 6, 30],\n [53, 45, 107, 1237, 2452, 6, 30, 3350],\n [53, 45, 107, 1237, 2452, 6, 30, 3350, 1663],\n [3351, 122],\n [3351, 122, 36],\n [3351, 122, 36, 1113],\n [3351, 122, 36, 1113, 1238],\n [3351, 122, 36, 1113, 1238, 18],\n [3351, 122, 36, 1113, 1238, 18, 20],\n [3351, 122, 36, 1113, 1238, 18, 20, 210],\n [3351, 122, 36, 1113, 1238, 18, 20, 210, 1972],\n [3351, 122, 36, 1113, 1238, 18, 20, 210, 1972, 683],\n [18, 53],\n [18, 53, 497],\n [18, 53, 497, 20],\n [18, 53, 497, 20, 726],\n [18, 53, 497, 20, 726, 13],\n [18, 53, 497, 20, 726, 13, 39],\n [18, 53, 497, 20, 726, 13, 39, 251],\n [18, 53, 497, 20, 726, 13, 39, 251, 23],\n [18, 53, 497, 20, 726, 13, 39, 251, 23, 309],\n [18, 53, 497, 20, 726, 13, 39, 251, 23, 309, 130],\n [18, 53, 497, 20, 726, 13, 39, 251, 23, 309, 130, 64],\n [18, 53, 497, 20, 726, 13, 39, 251, 23, 309, 130, 64, 268],\n [34, 13],\n [34, 13, 9],\n [34, 13, 9, 15],\n [34, 13, 9, 15, 26],\n [34, 13, 9, 15, 26, 30],\n [34, 13, 9, 15, 26, 30, 62],\n [34, 13, 9, 15, 26, 30, 62, 1664],\n [34, 13, 9, 15, 26, 30, 62, 1664, 2],\n [34, 13, 9, 15, 26, 30, 62, 1664, 2, 61],\n [34, 13, 9, 15, 26, 30, 62, 1664, 2, 61, 145],\n [34, 13, 9, 15, 26, 30, 62, 1664, 2, 61, 145, 9],\n [34, 13, 9, 15, 26, 30, 62, 1664, 2, 61, 145, 9, 1239],\n [24, 2445],\n [24, 2445, 2],\n [24, 2445, 2, 25],\n [24, 2445, 2, 25, 16],\n [24, 2445, 2, 25, 16, 7],\n [24, 2445, 2, 25, 16, 7, 243],\n [24, 2445, 2, 25, 16, 7, 243, 4],\n [24, 2445, 2, 25, 16, 7, 243, 4, 8],\n [24, 2445, 2, 25, 16, 7, 243, 4, 8, 915],\n [24, 2445, 2, 25, 16, 7, 243, 4, 8, 915, 841],\n [3, 310],\n [3, 310, 3],\n [3, 310, 3, 57],\n [3, 310, 3, 57, 30],\n [3, 310, 3, 57, 30, 517],\n [3, 310, 3, 57, 30, 517, 3],\n [3, 310, 3, 57, 30, 517, 3, 30],\n [3, 310, 3, 57, 30, 517, 3, 30, 147],\n [3, 310, 3, 57, 30, 517, 3, 30, 147, 122],\n [8, 499],\n [8, 499, 9],\n [8, 499, 9, 111],\n [8, 499, 9, 111, 26],\n [8, 499, 9, 111, 26, 91],\n [8, 499, 9, 111, 26, 91, 3],\n [8, 499, 9, 111, 26, 91, 3, 31],\n [8, 499, 9, 111, 26, 91, 3, 31, 9],\n [8, 499, 9, 111, 26, 91, 3, 31, 9, 222],\n [8, 499, 9, 111, 26, 91, 3, 31, 9, 222, 36],\n [8, 499, 9, 111, 26, 91, 3, 31, 9, 222, 36, 215],\n [100, 1240],\n [100, 1240, 20],\n [100, 1240, 20, 107],\n [100, 1240, 20, 107, 87],\n [100, 1240, 20, 107, 87, 300],\n [100, 1240, 20, 107, 87, 300, 32],\n [100, 1240, 20, 107, 87, 300, 32, 4],\n [100, 1240, 20, 107, 87, 300, 32, 4, 30],\n [100, 1240, 20, 107, 87, 300, 32, 4, 30, 908],\n [100, 1240, 20, 107, 87, 300, 32, 4, 30, 908, 521],\n [103, 9],\n [103, 9, 1665],\n [103, 9, 1665, 5],\n [103, 9, 1665, 5, 71],\n [103, 9, 1665, 5, 71, 1666],\n [103, 9, 1665, 5, 71, 1666, 776],\n [103, 9, 1665, 5, 71, 1666, 776, 33],\n [103, 9, 1665, 5, 71, 1666, 776, 33, 1427],\n [43, 81],\n [43, 81, 110],\n [43, 81, 110, 19],\n [43, 81, 110, 19, 29],\n [43, 81, 110, 19, 29, 21],\n [43, 81, 110, 19, 29, 21, 51],\n [43, 81, 110, 19, 29, 21, 51, 1114],\n [43, 81, 110, 19, 29, 21, 51, 1114, 4],\n [43, 81, 110, 19, 29, 21, 51, 1114, 4, 183],\n [43, 81, 110, 19, 29, 21, 51, 1114, 4, 183, 3],\n [43, 81, 110, 19, 29, 21, 51, 1114, 4, 183, 3, 1667],\n [4, 227],\n [4, 227, 34],\n [4, 227, 34, 54],\n [4, 227, 34, 54, 23],\n [4, 227, 34, 54, 23, 728],\n [4, 227, 34, 54, 23, 728, 8],\n [4, 227, 34, 54, 23, 728, 8, 372],\n [4, 227, 34, 54, 23, 728, 8, 372, 21],\n [4, 227, 34, 54, 23, 728, 8, 372, 21, 64],\n [4, 227, 34, 54, 23, 728, 8, 372, 21, 64, 282],\n [4, 462],\n [4, 462, 500],\n [4, 462, 500, 7],\n [4, 462, 500, 7, 522],\n [4, 462, 500, 7, 522, 21],\n [4, 462, 500, 7, 522, 21, 292],\n [4, 462, 500, 7, 522, 21, 292, 125],\n [4, 462, 500, 7, 522, 21, 292, 125, 45],\n [4, 462, 500, 7, 522, 21, 292, 125, 45, 163],\n [8, 322],\n [8, 322, 9],\n [8, 322, 9, 38],\n [8, 322, 9, 38, 1668],\n [8, 322, 9, 38, 1668, 8],\n [8, 322, 9, 38, 1668, 8, 1428],\n [8, 322, 9, 38, 1668, 8, 1428, 7],\n [8, 322, 9, 38, 1668, 8, 1428, 7, 111],\n [8, 322, 9, 38, 1668, 8, 1428, 7, 111, 2],\n [8, 322, 9, 38, 1668, 8, 1428, 7, 111, 2, 150],\n [8, 322, 9, 38, 1668, 8, 1428, 7, 111, 2, 150, 152],\n [10, 7],\n [10, 7, 58],\n [10, 7, 58, 29],\n [2, 59],\n [2, 59, 104],\n [2, 59, 104, 186],\n [2, 59, 104, 186, 10],\n [2, 59, 104, 186, 10, 7],\n [2, 59, 104, 186, 10, 7, 5],\n [2, 59, 104, 186, 10, 7, 5, 100],\n [2, 59, 104, 186, 10, 7, 5, 100, 210],\n [2, 59, 104, 186, 10, 7, 5, 100, 210, 3],\n [2, 59, 104, 186, 10, 7, 5, 100, 210, 3, 604],\n [2, 59, 104, 186, 10, 7, 5, 100, 210, 3, 604, 1429],\n [842, 497],\n [842, 497, 1013],\n [842, 497, 1013, 3],\n [842, 497, 1013, 3, 155],\n [842, 497, 1013, 3, 155, 59],\n [842, 497, 1013, 3, 155, 59, 104],\n [842, 497, 1013, 3, 155, 59, 104, 581],\n [842, 497, 1013, 3, 155, 59, 104, 581, 47],\n [842, 497, 1013, 3, 155, 59, 104, 581, 47, 25],\n [19, 12],\n [19, 12, 7],\n [19, 12, 7, 58],\n [19, 12, 7, 58, 6],\n [19, 12, 7, 58, 6, 29],\n [19, 12, 7, 58, 6, 29, 16],\n [19, 12, 7, 58, 6, 29, 16, 10],\n [19, 12, 7, 58, 6, 29, 16, 10, 28],\n [19, 12, 7, 58, 6, 29, 16, 10, 28, 1115],\n [19, 12, 7, 58, 6, 29, 16, 10, 28, 1115, 1],\n [19, 12, 7, 58, 6, 29, 16, 10, 28, 1115, 1, 307],\n [19, 12, 7, 58, 6, 29, 16, 10, 28, 1115, 1, 307, 2],\n [19, 12, 7, 58, 6, 29, 16, 10, 28, 1115, 1, 307, 2, 3352],\n [19, 12, 7, 58, 6, 29, 16, 10, 28, 1115, 1, 307, 2, 3352, 90],\n [5, 189],\n [5, 189, 202],\n [5, 189, 202, 106],\n [5, 189, 202, 106, 29],\n [5, 189, 202, 106, 29, 49],\n [5, 189, 202, 106, 29, 49, 9],\n [5, 189, 202, 106, 29, 49, 9, 26],\n [5, 189, 202, 106, 29, 49, 9, 26, 5],\n [5, 189, 202, 106, 29, 49, 9, 26, 5, 30],\n [5, 189, 202, 106, 29, 49, 9, 26, 5, 30, 362],\n [5, 189, 202, 106, 29, 49, 9, 26, 5, 30, 362, 843],\n [19, 8],\n [19, 8, 1116],\n [19, 8, 1116, 9],\n [19, 8, 1116, 9, 3353],\n [19, 8, 1116, 9, 3353, 393],\n [19, 8, 1116, 9, 3353, 393, 3],\n [19, 8, 1116, 9, 3353, 393, 3, 17],\n [19, 8, 1116, 9, 3353, 393, 3, 17, 168],\n [19, 8, 1116, 9, 3353, 393, 3, 17, 168, 6],\n [19, 8, 1116, 9, 3353, 393, 3, 17, 168, 6, 164],\n [19, 8, 1116, 9, 3353, 393, 3, 17, 168, 6, 164, 1973],\n [8, 125],\n [8, 125, 9],\n [8, 125, 9, 143],\n [8, 125, 9, 143, 71],\n [8, 125, 9, 143, 71, 2],\n [8, 125, 9, 143, 71, 2, 1117],\n [8, 125, 9, 143, 71, 2, 1117, 6],\n [8, 125, 9, 143, 71, 2, 1117, 6, 8],\n [8, 125, 9, 143, 71, 2, 1117, 6, 8, 37],\n [8, 125, 9, 143, 71, 2, 1117, 6, 8, 37, 1241],\n [8, 125, 9, 143, 71, 2, 1117, 6, 8, 37, 1241, 394],\n [32, 8],\n [32, 8, 1974],\n [32, 8, 1974, 916],\n [32, 8, 1974, 916, 3],\n [32, 8, 1974, 916, 3, 3354],\n [32, 8, 1974, 916, 3, 3354, 1020],\n [32, 8, 1974, 916, 3, 3354, 1020, 311],\n [32, 8, 1974, 916, 3, 3354, 1020, 311, 41],\n [32, 8, 1974, 916, 3, 3354, 1020, 311, 41, 20],\n [32, 8, 1974, 916, 3, 3354, 1020, 311, 41, 20, 75],\n [44, 28],\n [44, 28, 14],\n [44, 28, 14, 88],\n [44, 28, 14, 88, 6],\n [44, 28, 14, 88, 6, 47],\n [44, 28, 14, 88, 6, 47, 79],\n [44, 28, 14, 88, 6, 47, 79, 16],\n [44, 28, 14, 88, 6, 47, 79, 16, 10],\n [44, 28, 14, 88, 6, 47, 79, 16, 10, 7],\n [44, 28, 14, 88, 6, 47, 79, 16, 10, 7, 1975],\n [44, 28, 14, 88, 6, 47, 79, 16, 10, 7, 1975, 3],\n [44, 28, 14, 88, 6, 47, 79, 16, 10, 7, 1975, 3, 2453],\n [2, 917],\n [2, 917, 20],\n [2, 917, 20, 1976],\n [2, 917, 20, 1976, 13],\n [2, 917, 20, 1976, 13, 9],\n [2, 917, 20, 1976, 13, 9, 80],\n [2, 917, 20, 1976, 13, 9, 80, 3355],\n [2, 917, 20, 1976, 13, 9, 80, 3355, 62],\n [2, 917, 20, 1976, 13, 9, 80, 3355, 62, 218],\n [2, 917, 20, 1976, 13, 9, 80, 3355, 62, 218, 13],\n [2, 917, 20, 1976, 13, 9, 80, 3355, 62, 218, 13, 9],\n [2, 917, 20, 1976, 13, 9, 80, 3355, 62, 218, 13, 9, 79],\n [2, 917, 20, 1976, 13, 9, 80, 3355, 62, 218, 13, 9, 79, 501],\n [4, 153],\n [4, 153, 1021],\n [4, 153, 1021, 8],\n [4, 153, 1021, 8, 269],\n [4, 153, 1021, 8, 269, 6],\n [4, 153, 1021, 8, 269, 6, 64],\n [4, 153, 1021, 8, 269, 6, 64, 87],\n [4, 153, 1021, 8, 269, 6, 64, 87, 2426],\n [4, 153, 1021, 8, 269, 6, 64, 87, 2426, 4],\n [4, 153, 1021, 8, 269, 6, 64, 87, 2426, 4, 20],\n [4, 153, 1021, 8, 269, 6, 64, 87, 2426, 4, 20, 1013],\n [4, 153, 1021, 8, 269, 6, 64, 87, 2426, 4, 20, 1013, 918],\n [25, 3356],\n [25, 3356, 4],\n [25, 3356, 4, 1430],\n [25, 3356, 4, 1430, 54],\n [25, 3356, 4, 1430, 54, 502],\n [25, 3356, 4, 1430, 54, 502, 21],\n [25, 3356, 4, 1430, 54, 502, 21, 145],\n [25, 3356, 4, 1430, 54, 502, 21, 145, 18],\n [25, 3356, 4, 1430, 54, 502, 21, 145, 18, 103],\n [25, 3356, 4, 1430, 54, 502, 21, 145, 18, 103, 9],\n [25, 3356, 4, 1430, 54, 502, 21, 145, 18, 103, 9, 844],\n [1431, 78],\n [1431, 78, 21],\n [1431, 78, 21, 51],\n [1431, 78, 21, 51, 236],\n [1431, 78, 21, 51, 236, 301],\n [1431, 78, 21, 51, 236, 301, 148],\n [1431, 78, 21, 51, 236, 301, 148, 4],\n [1431, 78, 21, 51, 236, 301, 148, 4, 1423],\n [1431, 78, 21, 51, 236, 301, 148, 4, 1423, 3],\n [523, 353],\n [523, 353, 3],\n [523, 353, 3, 9],\n [523, 353, 3, 9, 363],\n [523, 353, 3, 9, 363, 309],\n [523, 353, 3, 9, 363, 309, 25],\n [523, 353, 3, 9, 363, 309, 25, 1],\n [523, 353, 3, 9, 363, 309, 25, 1, 640],\n [523, 353, 3, 9, 363, 309, 25, 1, 640, 3],\n [523, 353, 3, 9, 363, 309, 25, 1, 640, 3, 302],\n [523, 353, 3, 9, 363, 309, 25, 1, 640, 3, 302, 501],\n [145, 39],\n [145, 39, 53],\n [145, 39, 53, 159],\n [145, 39, 53, 159, 45],\n [145, 39, 53, 159, 45, 87],\n [145, 39, 53, 159, 45, 87, 392],\n [145, 39, 53, 159, 45, 87, 392, 3357],\n [12, 524],\n ...]"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#Padding sequences\nmax_sequence_len = max([len(x) for x in input_sequences])\nmax_sequence_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.223645Z","iopub.execute_input":"2024-11-25T15:11:51.223926Z","iopub.status.idle":"2024-11-25T15:11:51.235193Z","shell.execute_reply.started":"2024-11-25T15:11:51.223901Z","shell.execute_reply":"2024-11-25T15:11:51.234354Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"18"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))\ninput_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.236279Z","iopub.execute_input":"2024-11-25T15:11:51.236565Z","iopub.status.idle":"2024-11-25T15:11:51.384335Z","shell.execute_reply.started":"2024-11-25T15:11:51.236518Z","shell.execute_reply":"2024-11-25T15:11:51.383591Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([[   0,    0,    0, ...,    0, 1103,   33],\n       [   0,    0,    0, ..., 1103,   33, 3293],\n       [   0,    0,    0, ...,   33, 3293, 3294],\n       ...,\n       [   0,    0,    0, ...,   52,    6,  164],\n       [   0,    0,    0, ...,    6,  164, 5873],\n       [   0,    0,    0, ...,  164, 5873,  776]], dtype=int32)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#Creation of predictors and labels\nX,y = input_sequences[:,:-1], input_sequences[:,-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.385154Z","iopub.execute_input":"2024-11-25T15:11:51.385379Z","iopub.status.idle":"2024-11-25T15:11:51.389655Z","shell.execute_reply.started":"2024-11-25T15:11:51.385357Z","shell.execute_reply":"2024-11-25T15:11:51.388603Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.390833Z","iopub.execute_input":"2024-11-25T15:11:51.391119Z","iopub.status.idle":"2024-11-25T15:11:51.401628Z","shell.execute_reply.started":"2024-11-25T15:11:51.391090Z","shell.execute_reply":"2024-11-25T15:11:51.400750Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([[   0,    0,    0, ...,    0,    0, 1103],\n       [   0,    0,    0, ...,    0, 1103,   33],\n       [   0,    0,    0, ..., 1103,   33, 3293],\n       ...,\n       [   0,    0,    0, ...,    0,   52,    6],\n       [   0,    0,    0, ...,   52,    6,  164],\n       [   0,    0,    0, ...,    6,  164, 5873]], dtype=int32)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.402526Z","iopub.execute_input":"2024-11-25T15:11:51.402804Z","iopub.status.idle":"2024-11-25T15:11:51.411234Z","shell.execute_reply.started":"2024-11-25T15:11:51.402780Z","shell.execute_reply":"2024-11-25T15:11:51.410414Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([  33, 3293, 3294, ...,  164, 5873,  776], dtype=int32)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"y = tf.keras.utils.to_categorical(y, num_classes = total_words)\ny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.412259Z","iopub.execute_input":"2024-11-25T15:11:51.412592Z","iopub.status.idle":"2024-11-25T15:11:51.629092Z","shell.execute_reply.started":"2024-11-25T15:11:51.412556Z","shell.execute_reply":"2024-11-25T15:11:51.628196Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.630101Z","iopub.execute_input":"2024-11-25T15:11:51.630379Z","iopub.status.idle":"2024-11-25T15:11:51.635908Z","shell.execute_reply.started":"2024-11-25T15:11:51.630353Z","shell.execute_reply":"2024-11-25T15:11:51.634970Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(76330, 5875)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"#Splitting the data into train and validation split\nXtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size = 0.20)\nXtrain.shape,Xtest.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:11:51.636970Z","iopub.execute_input":"2024-11-25T15:11:51.637213Z","iopub.status.idle":"2024-11-25T15:11:53.727902Z","shell.execute_reply.started":"2024-11-25T15:11:51.637174Z","shell.execute_reply":"2024-11-25T15:11:53.727025Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"((61064, 17), (15266, 17))"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"#Defining early Stopping\nearly_stopping = EarlyStopping(\n    monitor='val_loss',        # Monitor the validation loss\n    patience=20,               # Allow up to 20 epochs without improvement\n    restore_best_weights=True, # Restore the weights from the best epoch\n    min_delta=0.01,            # Consider only changes greater than 0.01 as improvements\n    verbose=1,                 # Print a message when early stopping is triggered\n    mode='auto'                # Automatically choose the mode based on the metric\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:34:44.248181Z","iopub.execute_input":"2024-11-25T15:34:44.248551Z","iopub.status.idle":"2024-11-25T15:34:44.254996Z","shell.execute_reply.started":"2024-11-25T15:34:44.248507Z","shell.execute_reply":"2024-11-25T15:34:44.254062Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"total_words, max_sequence_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:34:44.578802Z","iopub.execute_input":"2024-11-25T15:34:44.579100Z","iopub.status.idle":"2024-11-25T15:34:44.585164Z","shell.execute_reply.started":"2024-11-25T15:34:44.579072Z","shell.execute_reply":"2024-11-25T15:34:44.584227Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(5875, 18)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Training LSTM Model\n# Don't forget to use input_dim, output_dim \nmodel = Sequential()\nmodel.add(Embedding(input_dim = total_words, output_dim = 150, input_shape=(max_sequence_len-1,)))  # Remove input_length if possible\nmodel.add(LSTM(200, return_sequences=True))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(150))\nmodel.add(Dense(total_words, activation='softmax'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:43:25.627103Z","iopub.execute_input":"2024-11-25T15:43:25.627432Z","iopub.status.idle":"2024-11-25T15:43:25.699623Z","shell.execute_reply.started":"2024-11-25T15:43:25.627401Z","shell.execute_reply":"2024-11-25T15:43:25.698929Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:43:25.782969Z","iopub.execute_input":"2024-11-25T15:43:25.783485Z","iopub.status.idle":"2024-11-25T15:43:25.790334Z","shell.execute_reply.started":"2024-11-25T15:43:25.783456Z","shell.execute_reply":"2024-11-25T15:43:25.789612Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:43:25.940968Z","iopub.execute_input":"2024-11-25T15:43:25.941192Z","iopub.status.idle":"2024-11-25T15:43:25.957566Z","shell.execute_reply.started":"2024-11-25T15:43:25.941170Z","shell.execute_reply":"2024-11-25T15:43:25.956737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n\n embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m150\u001b[0m)               \u001b[38;5;34m881,250\u001b[0m \n\n lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m200\u001b[0m)               \u001b[38;5;34m280,800\u001b[0m \n\n dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m200\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n\n lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                   \u001b[38;5;34m210,600\u001b[0m \n\n dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5875\u001b[0m)                  \u001b[38;5;34m887,125\u001b[0m \n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n\n embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">881,250</span> \n\n lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">280,800</span> \n\n dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n\n lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">210,600</span> \n\n dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5875</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">887,125</span> \n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,259,775\u001b[0m (8.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,775</span> (8.62 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,259,775\u001b[0m (8.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,775</span> (8.62 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"#Training the Model\nhistory = model.fit(Xtrain,ytrain, epochs = 150, validation_data = (Xtest,ytest), verbose = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:43:26.377236Z","iopub.execute_input":"2024-11-25T15:43:26.377487Z","iopub.status.idle":"2024-11-25T16:30:47.370444Z","shell.execute_reply.started":"2024-11-25T15:43:26.377463Z","shell.execute_reply":"2024-11-25T16:30:47.369697Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.0395 - loss: 6.6865 - val_accuracy: 0.0702 - val_loss: 6.1682\nEpoch 2/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.0751 - loss: 5.9623 - val_accuracy: 0.1034 - val_loss: 5.8748\nEpoch 3/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1132 - loss: 5.5169 - val_accuracy: 0.1188 - val_loss: 5.7825\nEpoch 4/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1317 - loss: 5.2581 - val_accuracy: 0.1266 - val_loss: 5.7726\nEpoch 5/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1389 - loss: 5.0758 - val_accuracy: 0.1287 - val_loss: 5.8076\nEpoch 6/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1456 - loss: 4.9133 - val_accuracy: 0.1315 - val_loss: 5.8833\nEpoch 7/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1501 - loss: 4.7531 - val_accuracy: 0.1334 - val_loss: 5.9814\nEpoch 8/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1565 - loss: 4.6164 - val_accuracy: 0.1328 - val_loss: 6.0904\nEpoch 9/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1630 - loss: 4.4988 - val_accuracy: 0.1334 - val_loss: 6.2141\nEpoch 10/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1665 - loss: 4.3698 - val_accuracy: 0.1348 - val_loss: 6.3335\nEpoch 11/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1705 - loss: 4.2707 - val_accuracy: 0.1345 - val_loss: 6.4595\nEpoch 12/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1817 - loss: 4.1473 - val_accuracy: 0.1371 - val_loss: 6.5959\nEpoch 13/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1899 - loss: 4.0560 - val_accuracy: 0.1324 - val_loss: 6.7136\nEpoch 14/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.1982 - loss: 3.9598 - val_accuracy: 0.1319 - val_loss: 6.8332\nEpoch 15/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2105 - loss: 3.8700 - val_accuracy: 0.1300 - val_loss: 6.9465\nEpoch 16/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2157 - loss: 3.7868 - val_accuracy: 0.1307 - val_loss: 7.0841\nEpoch 17/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2236 - loss: 3.7205 - val_accuracy: 0.1276 - val_loss: 7.1938\nEpoch 18/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2336 - loss: 3.6441 - val_accuracy: 0.1263 - val_loss: 7.2818\nEpoch 19/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2415 - loss: 3.5870 - val_accuracy: 0.1256 - val_loss: 7.3684\nEpoch 20/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2477 - loss: 3.5257 - val_accuracy: 0.1246 - val_loss: 7.4838\nEpoch 21/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2574 - loss: 3.4651 - val_accuracy: 0.1228 - val_loss: 7.5813\nEpoch 22/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2654 - loss: 3.4027 - val_accuracy: 0.1215 - val_loss: 7.6514\nEpoch 23/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2742 - loss: 3.3530 - val_accuracy: 0.1210 - val_loss: 7.7380\nEpoch 24/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2830 - loss: 3.2926 - val_accuracy: 0.1231 - val_loss: 7.8407\nEpoch 25/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2893 - loss: 3.2533 - val_accuracy: 0.1207 - val_loss: 7.9077\nEpoch 26/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.2915 - loss: 3.2231 - val_accuracy: 0.1199 - val_loss: 7.9738\nEpoch 27/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3054 - loss: 3.1556 - val_accuracy: 0.1184 - val_loss: 8.0840\nEpoch 28/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3098 - loss: 3.1200 - val_accuracy: 0.1200 - val_loss: 8.1722\nEpoch 29/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3181 - loss: 3.0795 - val_accuracy: 0.1178 - val_loss: 8.2381\nEpoch 30/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3261 - loss: 3.0267 - val_accuracy: 0.1157 - val_loss: 8.2995\nEpoch 31/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3309 - loss: 2.9919 - val_accuracy: 0.1152 - val_loss: 8.3897\nEpoch 32/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3380 - loss: 2.9543 - val_accuracy: 0.1160 - val_loss: 8.4361\nEpoch 33/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3451 - loss: 2.9134 - val_accuracy: 0.1119 - val_loss: 8.5279\nEpoch 34/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3463 - loss: 2.8988 - val_accuracy: 0.1135 - val_loss: 8.5735\nEpoch 35/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3580 - loss: 2.8414 - val_accuracy: 0.1160 - val_loss: 8.6633\nEpoch 36/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3608 - loss: 2.8135 - val_accuracy: 0.1112 - val_loss: 8.7287\nEpoch 37/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3716 - loss: 2.7729 - val_accuracy: 0.1133 - val_loss: 8.7886\nEpoch 38/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3770 - loss: 2.7344 - val_accuracy: 0.1110 - val_loss: 8.8671\nEpoch 39/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3817 - loss: 2.7218 - val_accuracy: 0.1110 - val_loss: 8.9315\nEpoch 40/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3832 - loss: 2.6789 - val_accuracy: 0.1109 - val_loss: 8.9788\nEpoch 41/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3894 - loss: 2.6576 - val_accuracy: 0.1118 - val_loss: 9.0565\nEpoch 42/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4006 - loss: 2.6104 - val_accuracy: 0.1108 - val_loss: 9.1150\nEpoch 43/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.3991 - loss: 2.5979 - val_accuracy: 0.1097 - val_loss: 9.1552\nEpoch 44/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4068 - loss: 2.5626 - val_accuracy: 0.1074 - val_loss: 9.2279\nEpoch 45/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4123 - loss: 2.5439 - val_accuracy: 0.1040 - val_loss: 9.2614\nEpoch 46/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4172 - loss: 2.5212 - val_accuracy: 0.1077 - val_loss: 9.3654\nEpoch 47/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4216 - loss: 2.4836 - val_accuracy: 0.1091 - val_loss: 9.4071\nEpoch 48/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4269 - loss: 2.4624 - val_accuracy: 0.1070 - val_loss: 9.4594\nEpoch 49/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4311 - loss: 2.4415 - val_accuracy: 0.1074 - val_loss: 9.5431\nEpoch 50/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4357 - loss: 2.4120 - val_accuracy: 0.1041 - val_loss: 9.5844\nEpoch 51/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4378 - loss: 2.3953 - val_accuracy: 0.1028 - val_loss: 9.6357\nEpoch 52/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4475 - loss: 2.3612 - val_accuracy: 0.1027 - val_loss: 9.6988\nEpoch 53/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4478 - loss: 2.3408 - val_accuracy: 0.1029 - val_loss: 9.7492\nEpoch 54/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4601 - loss: 2.2968 - val_accuracy: 0.1034 - val_loss: 9.8096\nEpoch 55/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4594 - loss: 2.2996 - val_accuracy: 0.1066 - val_loss: 9.8677\nEpoch 56/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4653 - loss: 2.2623 - val_accuracy: 0.1024 - val_loss: 9.9178\nEpoch 57/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4633 - loss: 2.2460 - val_accuracy: 0.1034 - val_loss: 9.9653\nEpoch 58/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4704 - loss: 2.2445 - val_accuracy: 0.1023 - val_loss: 10.0035\nEpoch 59/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4782 - loss: 2.2064 - val_accuracy: 0.1030 - val_loss: 10.0738\nEpoch 60/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4783 - loss: 2.1990 - val_accuracy: 0.1024 - val_loss: 10.1267\nEpoch 61/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4770 - loss: 2.1993 - val_accuracy: 0.0978 - val_loss: 10.1546\nEpoch 62/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4872 - loss: 2.1510 - val_accuracy: 0.1009 - val_loss: 10.2376\nEpoch 63/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4877 - loss: 2.1374 - val_accuracy: 0.1006 - val_loss: 10.2470\nEpoch 64/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4963 - loss: 2.1145 - val_accuracy: 0.0990 - val_loss: 10.2724\nEpoch 65/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4973 - loss: 2.0980 - val_accuracy: 0.1026 - val_loss: 10.3971\nEpoch 66/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.4972 - loss: 2.0845 - val_accuracy: 0.0971 - val_loss: 10.4157\nEpoch 67/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5046 - loss: 2.0573 - val_accuracy: 0.1019 - val_loss: 10.4538\nEpoch 68/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5057 - loss: 2.0589 - val_accuracy: 0.0987 - val_loss: 10.4783\nEpoch 69/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5070 - loss: 2.0348 - val_accuracy: 0.0985 - val_loss: 10.5335\nEpoch 70/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5123 - loss: 2.0216 - val_accuracy: 0.0985 - val_loss: 10.5705\nEpoch 71/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5171 - loss: 2.0083 - val_accuracy: 0.0988 - val_loss: 10.6621\nEpoch 72/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5207 - loss: 1.9729 - val_accuracy: 0.0969 - val_loss: 10.6672\nEpoch 73/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5214 - loss: 1.9770 - val_accuracy: 0.0950 - val_loss: 10.7065\nEpoch 74/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5258 - loss: 1.9550 - val_accuracy: 0.0981 - val_loss: 10.7612\nEpoch 75/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5287 - loss: 1.9361 - val_accuracy: 0.0964 - val_loss: 10.8012\nEpoch 76/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5281 - loss: 1.9332 - val_accuracy: 0.0970 - val_loss: 10.8696\nEpoch 77/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5335 - loss: 1.9228 - val_accuracy: 0.0956 - val_loss: 10.9100\nEpoch 78/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5369 - loss: 1.9112 - val_accuracy: 0.0933 - val_loss: 10.9218\nEpoch 79/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5422 - loss: 1.8790 - val_accuracy: 0.0949 - val_loss: 11.0073\nEpoch 80/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5395 - loss: 1.8805 - val_accuracy: 0.0962 - val_loss: 11.0307\nEpoch 81/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5450 - loss: 1.8575 - val_accuracy: 0.0949 - val_loss: 11.0577\nEpoch 82/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5466 - loss: 1.8496 - val_accuracy: 0.0928 - val_loss: 11.1284\nEpoch 83/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5522 - loss: 1.8320 - val_accuracy: 0.0943 - val_loss: 11.1320\nEpoch 84/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5519 - loss: 1.8285 - val_accuracy: 0.0954 - val_loss: 11.2007\nEpoch 85/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5559 - loss: 1.8295 - val_accuracy: 0.0952 - val_loss: 11.2249\nEpoch 86/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5582 - loss: 1.7926 - val_accuracy: 0.0931 - val_loss: 11.2581\nEpoch 87/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5598 - loss: 1.7917 - val_accuracy: 0.0926 - val_loss: 11.2911\nEpoch 88/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5645 - loss: 1.7859 - val_accuracy: 0.0971 - val_loss: 11.3642\nEpoch 89/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5658 - loss: 1.7707 - val_accuracy: 0.0937 - val_loss: 11.3807\nEpoch 90/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5652 - loss: 1.7647 - val_accuracy: 0.0945 - val_loss: 11.4366\nEpoch 91/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5674 - loss: 1.7555 - val_accuracy: 0.0935 - val_loss: 11.5089\nEpoch 92/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5708 - loss: 1.7248 - val_accuracy: 0.0903 - val_loss: 11.5202\nEpoch 93/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5733 - loss: 1.7338 - val_accuracy: 0.0932 - val_loss: 11.5289\nEpoch 94/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5772 - loss: 1.7158 - val_accuracy: 0.0940 - val_loss: 11.6180\nEpoch 95/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5771 - loss: 1.7001 - val_accuracy: 0.0932 - val_loss: 11.5956\nEpoch 96/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5747 - loss: 1.7156 - val_accuracy: 0.0925 - val_loss: 11.6900\nEpoch 97/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5789 - loss: 1.6967 - val_accuracy: 0.0910 - val_loss: 11.6686\nEpoch 98/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5825 - loss: 1.6899 - val_accuracy: 0.0952 - val_loss: 11.7910\nEpoch 99/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5814 - loss: 1.6784 - val_accuracy: 0.0952 - val_loss: 11.7880\nEpoch 100/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5887 - loss: 1.6473 - val_accuracy: 0.0918 - val_loss: 11.8252\nEpoch 101/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5896 - loss: 1.6565 - val_accuracy: 0.0930 - val_loss: 11.8258\nEpoch 102/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5865 - loss: 1.6617 - val_accuracy: 0.0941 - val_loss: 11.9026\nEpoch 103/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5905 - loss: 1.6397 - val_accuracy: 0.0924 - val_loss: 11.9530\nEpoch 104/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5911 - loss: 1.6325 - val_accuracy: 0.0956 - val_loss: 11.9476\nEpoch 105/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5939 - loss: 1.6220 - val_accuracy: 0.0933 - val_loss: 11.9786\nEpoch 106/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5956 - loss: 1.6215 - val_accuracy: 0.0936 - val_loss: 12.0471\nEpoch 107/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6006 - loss: 1.5930 - val_accuracy: 0.0897 - val_loss: 12.0397\nEpoch 108/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6002 - loss: 1.6002 - val_accuracy: 0.0901 - val_loss: 12.0380\nEpoch 109/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5992 - loss: 1.5892 - val_accuracy: 0.0926 - val_loss: 12.1039\nEpoch 110/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6048 - loss: 1.5768 - val_accuracy: 0.0912 - val_loss: 12.1288\nEpoch 111/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6008 - loss: 1.5856 - val_accuracy: 0.0909 - val_loss: 12.1692\nEpoch 112/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6025 - loss: 1.5855 - val_accuracy: 0.0906 - val_loss: 12.2055\nEpoch 113/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6121 - loss: 1.5542 - val_accuracy: 0.0905 - val_loss: 12.2156\nEpoch 114/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6140 - loss: 1.5456 - val_accuracy: 0.0905 - val_loss: 12.2167\nEpoch 115/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6092 - loss: 1.5571 - val_accuracy: 0.0903 - val_loss: 12.2826\nEpoch 116/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6080 - loss: 1.5460 - val_accuracy: 0.0892 - val_loss: 12.2781\nEpoch 117/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6120 - loss: 1.5464 - val_accuracy: 0.0907 - val_loss: 12.3578\nEpoch 118/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6160 - loss: 1.5266 - val_accuracy: 0.0893 - val_loss: 12.3833\nEpoch 119/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6160 - loss: 1.5140 - val_accuracy: 0.0923 - val_loss: 12.4036\nEpoch 120/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6187 - loss: 1.5123 - val_accuracy: 0.0922 - val_loss: 12.4825\nEpoch 121/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6182 - loss: 1.5157 - val_accuracy: 0.0924 - val_loss: 12.4613\nEpoch 122/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6165 - loss: 1.5119 - val_accuracy: 0.0905 - val_loss: 12.5002\nEpoch 123/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6228 - loss: 1.4920 - val_accuracy: 0.0911 - val_loss: 12.5287\nEpoch 124/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6270 - loss: 1.4905 - val_accuracy: 0.0928 - val_loss: 12.5397\nEpoch 125/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6205 - loss: 1.5044 - val_accuracy: 0.0891 - val_loss: 12.5746\nEpoch 126/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6229 - loss: 1.4890 - val_accuracy: 0.0902 - val_loss: 12.6355\nEpoch 127/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6302 - loss: 1.4655 - val_accuracy: 0.0882 - val_loss: 12.6913\nEpoch 128/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 1.4772 - val_accuracy: 0.0904 - val_loss: 12.7094\nEpoch 129/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6265 - loss: 1.4651 - val_accuracy: 0.0895 - val_loss: 12.7119\nEpoch 130/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6320 - loss: 1.4519 - val_accuracy: 0.0895 - val_loss: 12.7608\nEpoch 131/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6286 - loss: 1.4567 - val_accuracy: 0.0902 - val_loss: 12.7081\nEpoch 132/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6330 - loss: 1.4474 - val_accuracy: 0.0893 - val_loss: 12.7893\nEpoch 133/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6341 - loss: 1.4431 - val_accuracy: 0.0909 - val_loss: 12.8146\nEpoch 134/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6358 - loss: 1.4466 - val_accuracy: 0.0921 - val_loss: 12.8293\nEpoch 135/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6346 - loss: 1.4356 - val_accuracy: 0.0911 - val_loss: 12.8816\nEpoch 136/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6381 - loss: 1.4189 - val_accuracy: 0.0895 - val_loss: 12.8839\nEpoch 137/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6365 - loss: 1.4209 - val_accuracy: 0.0918 - val_loss: 12.9416\nEpoch 138/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6436 - loss: 1.4012 - val_accuracy: 0.0884 - val_loss: 12.9077\nEpoch 139/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6356 - loss: 1.4176 - val_accuracy: 0.0872 - val_loss: 12.9293\nEpoch 140/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6397 - loss: 1.4156 - val_accuracy: 0.0897 - val_loss: 13.0208\nEpoch 141/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6395 - loss: 1.4136 - val_accuracy: 0.0879 - val_loss: 13.0586\nEpoch 142/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6437 - loss: 1.3979 - val_accuracy: 0.0892 - val_loss: 13.0450\nEpoch 143/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6401 - loss: 1.3978 - val_accuracy: 0.0893 - val_loss: 13.0805\nEpoch 144/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6494 - loss: 1.3747 - val_accuracy: 0.0877 - val_loss: 13.1106\nEpoch 145/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6465 - loss: 1.3892 - val_accuracy: 0.0879 - val_loss: 13.0808\nEpoch 146/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6452 - loss: 1.3958 - val_accuracy: 0.0885 - val_loss: 13.1380\nEpoch 147/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6487 - loss: 1.3774 - val_accuracy: 0.0886 - val_loss: 13.2162\nEpoch 148/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6485 - loss: 1.3673 - val_accuracy: 0.0897 - val_loss: 13.2293\nEpoch 149/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6473 - loss: 1.3713 - val_accuracy: 0.0882 - val_loss: 13.2356\nEpoch 150/150\n\u001b[1m1909/1909\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6528 - loss: 1.3623 - val_accuracy: 0.0879 - val_loss: 13.2500\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"model.save('LSTM_Next_word.h5')\nimport pickle\nwith open('tokenizer.pickle','wb') as handle:\n    pickle.dump(tokenizer,handle,protocol = pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T16:32:50.265464Z","iopub.execute_input":"2024-11-25T16:32:50.266121Z","iopub.status.idle":"2024-11-25T16:32:50.366467Z","shell.execute_reply.started":"2024-11-25T16:32:50.266087Z","shell.execute_reply":"2024-11-25T16:32:50.365591Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"#Function to predict the next word\ndef predict_next_word(model,tokenizer,text, max_sequence_len):\n    token_list = tokenizer.texts_to_sequences([text])[0]\n    if len(token_list)>=max_sequence_len:\n        token_list = token_list[-(max_sequence_len-1):]\n    token_list = pad_sequences([token_list],maxlen= max_sequence_len-1,padding = 'pre')\n    predicted = model.predict(token_list,verbose = 1)\n    predicted_word_idx = np.argmax(predicted,axis = 1)\n    for word,index in tokenizer.word_index.items():\n        if index ==predicted_word_idx:\n            return word\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T16:32:51.617916Z","iopub.execute_input":"2024-11-25T16:32:51.618759Z","iopub.status.idle":"2024-11-25T16:32:51.623850Z","shell.execute_reply.started":"2024-11-25T16:32:51.618725Z","shell.execute_reply":"2024-11-25T16:32:51.622990Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"input_text = \"to be or not to be\"\nprint(f'Input: {input_text}')\nmax_sequence_len = model.input_shape[1]+1\nnext_word = predict_next_word(model,tokenizer,input_text,max_sequence_len)\nprint(f'Output:{next_word}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T16:32:53.419382Z","iopub.execute_input":"2024-11-25T16:32:53.419731Z","iopub.status.idle":"2024-11-25T16:32:53.634758Z","shell.execute_reply.started":"2024-11-25T16:32:53.419701Z","shell.execute_reply":"2024-11-25T16:32:53.633844Z"}},"outputs":[{"name":"stdout","text":"Input: to be or not to be\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\nOutput:in\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}